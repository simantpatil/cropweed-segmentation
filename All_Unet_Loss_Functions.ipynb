{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet_DL(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_DL, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc1 = self.enc1(x)                      # (B,64,H,W)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))   # (B,128,H/2,W/2)\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))   # (B,256,H/4,W/4)\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))   # (B,512,H/8,W/8)\n",
    "\n",
    "        # ---------------- Bridge ----------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B,1024,H/16,W/16)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                    # (B,512,H/8,W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)      # (B,1024,H/8,W/8)\n",
    "        dec4 = self.dec4(dec4)                     # (B,512,H/8,W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                      # (B,256,H/4,W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)      # (B,512,H/4,W/4)\n",
    "        dec3 = self.dec3(dec3)                     # (B,256,H/4,W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                      # (B,128,H/2,W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)      # (B,256,H/2,W/2)\n",
    "        dec2 = self.dec2(dec2)                     # (B,128,H/2,W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                      # (B,64,H,W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)      # (B,128,H,W)\n",
    "        dec1 = self.dec1(dec1)                     # (B,64,H,W)\n",
    "\n",
    "        # Output\n",
    "        out = self.out(dec1)                       # (B,out_channels,H,W)\n",
    "        return out\n",
    "\n",
    "def dice_loss(pred, target, smooth=1.0):\n",
    "    \"\"\"\n",
    "    Compute Dice Loss for multi-class segmentation.\n",
    "    \n",
    "    Parameters:\n",
    "      - pred: logits tensor of shape (B, C, H, W)\n",
    "      - target: tensor of shape (B, H, W) with class indices\n",
    "      - smooth: smoothing factor to avoid division by zero\n",
    "    \n",
    "    Returns:\n",
    "      - dice loss (1 - average dice score)\n",
    "    \"\"\"\n",
    "    # Apply softmax to logits to get class probabilities\n",
    "    pred_probs = F.softmax(pred, dim=1)  # (B, C, H, W)\n",
    "    \n",
    "    # One-hot encode the target\n",
    "    target_one_hot = F.one_hot(target, num_classes=pred.shape[1])  # (B, H, W, C)\n",
    "    target_one_hot = target_one_hot.permute(0, 3, 1, 2).float()      # (B, C, H, W)\n",
    "    \n",
    "    # Flatten the tensors\n",
    "    pred_flat = pred_probs.contiguous().view(pred_probs.shape[0], pred_probs.shape[1], -1)\n",
    "    target_flat = target_one_hot.contiguous().view(target_one_hot.shape[0], target_one_hot.shape[1], -1)\n",
    "    \n",
    "    intersection = (pred_flat * target_flat).sum(dim=2)\n",
    "    denominator = pred_flat.sum(dim=2) + target_flat.sum(dim=2)\n",
    "    \n",
    "    dice_score = (2 * intersection + smooth) / (denominator + smooth)\n",
    "    loss = 1 - dice_score.mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet_JL(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_JL, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc1 = self.enc1(x)                      # (B,64,H,W)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))   # (B,128,H/2,W/2)\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))   # (B,256,H/4,W/4)\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))   # (B,512,H/8,W/8)\n",
    "\n",
    "        # ---------------- Bridge ----------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B,1024,H/16,W/16)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                    # (B,512,H/8,W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)      # (B,1024,H/8,W/8)\n",
    "        dec4 = self.dec4(dec4)                     # (B,512,H/8,W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                      # (B,256,H/4,W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)      # (B,512,H/4,W/4)\n",
    "        dec3 = self.dec3(dec3)                     # (B,256,H/4,W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                      # (B,128,H/2,W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)      # (B,256,H/2,W/2)\n",
    "        dec2 = self.dec2(dec2)                     # (B,128,H/2,W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                      # (B,64,H,W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)      # (B,128,H,W)\n",
    "        dec1 = self.dec1(dec1)                     # (B,64,H,W)\n",
    "\n",
    "        # Output\n",
    "        out = self.out(dec1)                       # (B,out_channels,H,W)\n",
    "        return out\n",
    "\n",
    "def jaccard_loss(pred, target, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Computes the Jaccard Loss (IoU loss) for multi-class segmentation.\n",
    "    \n",
    "    Parameters:\n",
    "      - pred: logits tensor of shape (B, C, H, W)\n",
    "      - target: tensor of shape (B, H, W) with class indices\n",
    "      - smooth: smoothing constant to avoid division by zero\n",
    "      \n",
    "    Returns:\n",
    "      - Jaccard loss (1 - average Jaccard index across classes)\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities using softmax\n",
    "    pred_probs = F.softmax(pred, dim=1)  # shape: (B, C, H, W)\n",
    "    \n",
    "    # One-hot encode the target tensor\n",
    "    target_one_hot = F.one_hot(target, num_classes=pred.shape[1])  # (B, H, W, C)\n",
    "    target_one_hot = target_one_hot.permute(0, 3, 1, 2).float()      # (B, C, H, W)\n",
    "    \n",
    "    # Flatten the tensors: shape (B, C, H*W)\n",
    "    pred_flat = pred_probs.view(pred_probs.shape[0], pred_probs.shape[1], -1)\n",
    "    target_flat = target_one_hot.view(target_one_hot.shape[0], target_one_hot.shape[1], -1)\n",
    "    \n",
    "    intersection = (pred_flat * target_flat).sum(dim=2)\n",
    "    total = (pred_flat + target_flat).sum(dim=2)\n",
    "    union = total - intersection\n",
    "    \n",
    "    jaccard_index = (intersection + smooth) / (union + smooth)\n",
    "    loss = 1 - jaccard_index.mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet_FL(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_FL, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc1 = self.enc1(x)                      # (B,64,H,W)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))   # (B,128,H/2,W/2)\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))   # (B,256,H/4,W/4)\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))   # (B,512,H/8,W/8)\n",
    "\n",
    "        # ---------------- Bridge ----------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B,1024,H/16,W/16)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                    # (B,512,H/8,W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)      # (B,1024,H/8,W/8)\n",
    "        dec4 = self.dec4(dec4)                     # (B,512,H/8,W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                      # (B,256,H/4,W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)      # (B,512,H/4,W/4)\n",
    "        dec3 = self.dec3(dec3)                     # (B,256,H/4,W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                      # (B,128,H/2,W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)      # (B,256,H/2,W/2)\n",
    "        dec2 = self.dec2(dec2)                     # (B,128,H/2,W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                      # (B,64,H,W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)      # (B,128,H,W)\n",
    "        dec1 = self.dec1(dec1)                     # (B,64,H,W)\n",
    "\n",
    "        # Output\n",
    "        out = self.out(dec1)                       # (B,out_channels,H,W)\n",
    "        return out\n",
    "\n",
    "# ---------------- Focal Loss Implementation ----------------\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for multi-class classification.\n",
    "    \n",
    "    Args:\n",
    "        alpha (float): Weighting factor for the rare class. Default: 0.25.\n",
    "        gamma (float): Focusing parameter for modulating factor (1-p). Default: 2.0.\n",
    "        reduction (str): Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. Default: 'mean'.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (Tensor): Raw output logits from the model with shape (B, C, H, W).\n",
    "            targets (Tensor): Ground truth labels with shape (B, H, W) where each value is 0 ≤ targets[i] ≤ C-1.\n",
    "        \"\"\"\n",
    "        # Compute the standard cross entropy loss (without reduction)\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        # Compute the probability for the true class\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        # Compute the focal loss term\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet_TL(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_TL, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc1 = self.enc1(x)                      # (B,64,H,W)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))   # (B,128,H/2,W/2)\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))   # (B,256,H/4,W/4)\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))   # (B,512,H/8,W/8)\n",
    "\n",
    "        # ---------------- Bridge ----------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B,1024,H/16,W/16)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                    # (B,512,H/8,W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)      # (B,1024,H/8,W/8)\n",
    "        dec4 = self.dec4(dec4)                     # (B,512,H/8,W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                      # (B,256,H/4,W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)      # (B,512,H/4,W/4)\n",
    "        dec3 = self.dec3(dec3)                     # (B,256,H/4,W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                      # (B,128,H/2,W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)      # (B,256,H/2,W/2)\n",
    "        dec2 = self.dec2(dec2)                     # (B,128,H/2,W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                      # (B,64,H,W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)      # (B,128,H,W)\n",
    "        dec1 = self.dec1(dec1)                     # (B,64,H,W)\n",
    "\n",
    "        # Output\n",
    "        out = self.out(dec1)                       # (B,out_channels,H,W)\n",
    "        return out\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Tversky Loss for multi-class segmentation.\n",
    "    \n",
    "    The Tversky index is defined as:\n",
    "    \n",
    "        TI = TP / (TP + α * FN + β * FP)\n",
    "    \n",
    "    and the Tversky loss is:\n",
    "    \n",
    "        Loss = 1 - TI\n",
    "    \n",
    "    where:\n",
    "      - TP: True Positives\n",
    "      - FN: False Negatives\n",
    "      - FP: False Positives\n",
    "      - α, β: weights that control the penalty for FN and FP respectively.\n",
    "      \n",
    "    Typically, α + β = 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.5, beta=0.5, smooth=1e-6):\n",
    "        super(TverskyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (Tensor): Raw output logits from the model with shape (B, C, H, W).\n",
    "            targets (Tensor): Ground truth labels with shape (B, H, W) where each value is 0 ≤ targets[i] ≤ C-1.\n",
    "        \"\"\"\n",
    "        # Number of classes inferred from the model output\n",
    "        num_classes = inputs.size(1)\n",
    "        \n",
    "        # Convert targets to one-hot encoding with shape (B, C, H, W)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        # Apply softmax to get class probabilities\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        \n",
    "        # Compute the true positives, false negatives, and false positives per class\n",
    "        dims = (0, 2, 3)  # Sum over batch and spatial dimensions\n",
    "        true_pos  = torch.sum(probs * targets_one_hot, dims)\n",
    "        false_neg = torch.sum(targets_one_hot * (1 - probs), dims)\n",
    "        false_pos = torch.sum((1 - targets_one_hot) * probs, dims)\n",
    "        \n",
    "        # Compute the Tversky index for each class\n",
    "        tversky_index = (true_pos + self.smooth) / (true_pos + self.alpha * false_neg + self.beta * false_pos + self.smooth)\n",
    "        \n",
    "        # Tversky loss is 1 minus the Tversky index\n",
    "        loss = 1 - tversky_index\n",
    "        return loss.mean()\n",
    "\n",
    "# ---------------- Example Usage ----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lovász-Softmax Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --------------------- U-Net Model ---------------------\n",
    "class UNet_LSL(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_LSL, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc1 = self.enc1(x)                      # (B, 64, H, W)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))   # (B, 128, H/2, W/2)\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))   # (B, 256, H/4, W/4)\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))   # (B, 512, H/8, W/8)\n",
    "\n",
    "        # ---------------- Bridge ----------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B, 1024, H/16, W/16)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                    # (B, 512, H/8, W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)      # (B, 1024, H/8, W/8)\n",
    "        dec4 = self.dec4(dec4)                     # (B, 512, H/8, W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                      # (B, 256, H/4, W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)      # (B, 512, H/4, W/4)\n",
    "        dec3 = self.dec3(dec3)                     # (B, 256, H/4, W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                      # (B, 128, H/2, W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)      # (B, 256, H/2, W/2)\n",
    "        dec2 = self.dec2(dec2)                     # (B, 128, H/2, W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                      # (B, 64, H, W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)      # (B, 128, H, W)\n",
    "        dec1 = self.dec1(dec1)                     # (B, 64, H, W)\n",
    "\n",
    "        # Output\n",
    "        out = self.out(dec1)                       # (B, out_channels, H, W)\n",
    "        return out\n",
    "\n",
    "# ----------------- Lovász-Softmax Loss -----------------\n",
    "# Helper function: compute gradient of the Lovász extension w.r.t sorted errors\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovász extension.\n",
    "    \n",
    "    Args:\n",
    "        gt_sorted (Tensor): Ground truth labels sorted in descending order of prediction errors.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: Gradients.\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1:\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[:-1]\n",
    "    return jaccard\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in shape [B, C, H, W] and labels in shape [B, H, W]\n",
    "    to [P, C] and [P] respectively.\n",
    "    \n",
    "    Args:\n",
    "        probas (Tensor): Class probabilities (after softmax) with shape (B, C, H, W).\n",
    "        labels (Tensor): Ground truth labels with shape (B, H, W).\n",
    "        ignore (int, optional): Label to ignore.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Tensor, Tensor]: Flattened probabilities and labels.\n",
    "    \"\"\"\n",
    "    if ignore is None:\n",
    "        probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, probas.size(1))\n",
    "        labels = labels.view(-1)\n",
    "    else:\n",
    "        mask = labels != ignore\n",
    "        probas = probas.permute(0, 2, 3, 1)[mask].contiguous().view(-1, probas.size(1))\n",
    "        labels = labels[mask]\n",
    "    return probas, labels\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes='present'):\n",
    "    \"\"\"\n",
    "    Computes the Lovász-Softmax loss from flattened predictions and labels.\n",
    "    \n",
    "    Args:\n",
    "        probas (Tensor): Flattened class probabilities, shape [P, C].\n",
    "        labels (Tensor): Flattened ground truth labels, shape [P].\n",
    "        classes (str or list): 'present' to compute loss only over classes present in labels,\n",
    "                               or a list of classes to average over.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: Lovász-Softmax loss.\n",
    "    \"\"\"\n",
    "    if probas.numel() == 0:\n",
    "        # Only void pixels, the loss is zero\n",
    "        return probas * 0.\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = (labels == c).float()  # foreground for class c\n",
    "        if classes == 'present' and fg.sum() == 0:\n",
    "            continue\n",
    "        errors = torch.abs(fg - probas[:, c])\n",
    "        errors_sorted, perm = torch.sort(errors, descending=True)\n",
    "        fg_sorted = fg[perm]\n",
    "        grad = lovasz_grad(fg_sorted)\n",
    "        losses.append(torch.dot(errors_sorted, grad))\n",
    "    if len(losses) == 0:\n",
    "        # If no class is present, return zero\n",
    "        return torch.tensor(0.).to(probas.device)\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovász-Softmax loss.\n",
    "    \n",
    "    Args:\n",
    "        probas (Tensor): Class probabilities at each pixel, shape [B, C, H, W].\n",
    "        labels (Tensor): Ground truth labels, shape [B, H, W].\n",
    "        classes (str or list): See lovasz_softmax_flat.\n",
    "        per_image (bool): Compute the loss per image instead of per batch.\n",
    "        ignore (int, optional): Label to ignore.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: Lovász-Softmax loss.\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = torch.mean(\n",
    "            torch.stack([\n",
    "                lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)\n",
    "                for prob, lab in zip(probas, labels)\n",
    "            ])\n",
    "        )\n",
    "        return loss\n",
    "    else:\n",
    "        probas, labels = flatten_probas(probas, labels, ignore)\n",
    "        return lovasz_softmax_flat(probas, labels, classes=classes)\n",
    "\n",
    "class LovaszSoftmaxLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Lovász-Softmax loss module.\n",
    "    \n",
    "    Args:\n",
    "        per_image (bool): Whether to compute the loss per image.\n",
    "        ignore_index (int, optional): Label to ignore.\n",
    "        classes (str or list): Which classes to include in the loss computation.\n",
    "    \"\"\"\n",
    "    def __init__(self, per_image=False, ignore_index=None, classes='present'):\n",
    "        super(LovaszSoftmaxLoss, self).__init__()\n",
    "        self.per_image = per_image\n",
    "        self.ignore_index = ignore_index\n",
    "        self.classes = classes\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        # Compute class probabilities\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        loss = lovasz_softmax(probas, labels, classes=self.classes,\n",
    "                              per_image=self.per_image, ignore=self.ignore_index)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import gc  # For garbage collection\n",
    "\n",
    "IMG_HEIGHT = 640\n",
    "IMG_WIDTH = 640\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 3\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 10  # Early stopping\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "IMAGE_DIR = 'CWD-3HSV/train/images'\n",
    "MASK_DIR  = 'CWD-3HSV/train/Morphed_Images'\n",
    "VALID_IMAGE_DIR = 'CWD-3HSV/valid/images'\n",
    "VALID_MASK_DIR  = 'CWD-3HSV/valid/Morphed_Images'\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_files, mask_files, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.mask_files  = mask_files\n",
    "        self.transform   = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path  = self.image_files[idx]\n",
    "        mask_path = self.mask_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask  = Image.open(mask_path).convert('L')\n",
    "\n",
    "        # Resize\n",
    "        image = image.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        mask  = mask.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask  = torch.tensor(np.array(mask), dtype=torch.long)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Prepare training file paths\n",
    "image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith('.jpg')]\n",
    "mask_files  = [f.replace('.jpg', '_morphed.png') for f in image_files]\n",
    "\n",
    "valid_image_files = []\n",
    "valid_mask_files  = []\n",
    "for img_file in image_files:\n",
    "    mask_file = img_file.replace('.jpg', '_morphed.png')\n",
    "    if mask_file in os.listdir(MASK_DIR):\n",
    "        valid_image_files.append(os.path.join(IMAGE_DIR, img_file))\n",
    "        valid_mask_files.append(os.path.join(MASK_DIR,  mask_file))\n",
    "\n",
    "val_image_files = [os.path.join(VALID_IMAGE_DIR, f) for f in os.listdir(VALID_IMAGE_DIR) if f.endswith('.jpg')]\n",
    "val_mask_files  = [os.path.join(VALID_MASK_DIR,  f.replace('.jpg', '_morphed.png'))\n",
    "                   for f in os.listdir(VALID_IMAGE_DIR) if f.endswith('.jpg')]\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = SegmentationDataset(valid_image_files, valid_mask_files, transform=transform)\n",
    "val_dataset   = SegmentationDataset(val_image_files,   val_mask_files,   transform=transform)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader    = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "def calculate_iou(outputs, masks, num_classes):\n",
    "    # outputs: (B, num_classes, H, W)\n",
    "    outputs = torch.argmax(outputs, dim=1)\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = ((outputs == cls) & (masks == cls)).sum().item()\n",
    "        union        = ((outputs == cls) | (masks == cls)).sum().item()\n",
    "        if union == 0:\n",
    "            iou_per_class.append(float('nan'))\n",
    "        else:\n",
    "            iou_per_class.append(intersection / union)\n",
    "    return np.nanmean(iou_per_class)\n",
    "\n",
    "def calculate_iou_loss(outputs, masks, num_classes):\n",
    "    # 1 - mean IoU\n",
    "    iou = calculate_iou(outputs, masks, num_classes)\n",
    "    return 1 - iou\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss     = 0.0\n",
    "    running_iou_loss = 0.0\n",
    "    correct          = 0\n",
    "    total            = 0\n",
    "    iou_score        = 0\n",
    "\n",
    "    for images, masks in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs  = model(images)\n",
    "        loss     = criterion(outputs, masks)\n",
    "        iou_loss = calculate_iou_loss(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss     += loss.item()\n",
    "        running_iou_loss += iou_loss\n",
    "        _, predicted     = torch.max(outputs, 1)\n",
    "        total           += masks.numel()\n",
    "        correct         += (predicted == masks).sum().item()\n",
    "        iou_score       += calculate_iou(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "    epoch_loss      = running_loss / len(data_loader)\n",
    "    epoch_iou_loss  = running_iou_loss / len(data_loader)\n",
    "    epoch_accuracy  = correct / total * 100\n",
    "    epoch_iou       = iou_score / len(data_loader)\n",
    "    return epoch_loss, epoch_accuracy, epoch_iou, epoch_iou_loss\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss     = 0.0\n",
    "    running_iou_loss = 0.0\n",
    "    correct          = 0\n",
    "    total            = 0\n",
    "    iou_score        = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(data_loader, desc=\"Validation\", leave=False):\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "            outputs  = model(images)\n",
    "            loss     = criterion(outputs, masks)\n",
    "            iou_loss = calculate_iou_loss(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "            running_loss     += loss.item()\n",
    "            running_iou_loss += iou_loss\n",
    "            _, predicted     = torch.max(outputs, 1)\n",
    "            total           += masks.numel()\n",
    "            correct         += (predicted == masks).sum().item()\n",
    "            iou_score       += calculate_iou(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "    epoch_loss      = running_loss / len(data_loader)\n",
    "    epoch_iou_loss  = running_iou_loss / len(data_loader)\n",
    "    epoch_accuracy  = correct / total * 100\n",
    "    epoch_iou       = iou_score / len(data_loader)\n",
    "    return epoch_loss, epoch_accuracy, epoch_iou, epoch_iou_loss\n",
    "\n",
    "def train_and_evaluate_model(model_name, model_class, \n",
    "                             train_loader, val_loader,\n",
    "                             epochs=EPOCHS, patience=PATIENCE):\n",
    "    \"\"\"\n",
    "    Train a given model with the specified name/class \n",
    "    and store best model + metrics in a separate folder.\n",
    "    \"\"\"\n",
    "    # 1) Create directory for this model\n",
    "    model_dir = model_name\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Instantiate model + move to device\n",
    "    model = model_class(in_channels=3, out_channels=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "    # 3) Define optimizer + loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss   = float('inf')\n",
    "    best_model_path = None\n",
    "    patience_counter= 0\n",
    "    records         = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n[{model_name}] Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        train_loss, train_accuracy, train_iou, train_iou_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Train IoU: {train_iou:.4f}, Train IoU Loss: {train_iou_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_accuracy, val_iou, val_iou_loss = evaluate(model, val_loader, criterion)\n",
    "        print(f\"Val Loss:   {val_loss:.4f}, Val Accuracy:   {val_accuracy:.2f}%, \"\n",
    "              f\"Val IoU:   {val_iou:.4f}, Val IoU Loss:   {val_iou_loss:.4f}\")\n",
    "\n",
    "        records.append([\n",
    "            epoch+1, \n",
    "            train_loss, \n",
    "            train_accuracy, \n",
    "            val_loss, \n",
    "            val_accuracy, \n",
    "            train_iou_loss, \n",
    "            train_iou, \n",
    "            val_iou_loss, \n",
    "            val_iou\n",
    "        ])\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "            torch.save(model, best_model_path)\n",
    "            print(f\"  [*] Best model saved at {best_model_path}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  [!] Early stopping for {model_name}\")\n",
    "            break\n",
    "\n",
    "    # 4) Save Training_Metrics.xlsx in model_dir\n",
    "    excel_path = os.path.join(model_dir, \"Training_Metrics.xlsx\")\n",
    "    columns = [\n",
    "        \"Epoch\", \n",
    "        \"Training Loss\", \n",
    "        \"Training Accuracy\", \n",
    "        \"Validation Loss\", \n",
    "        \"Validation Accuracy\", \n",
    "        \"Training IoU loss\", \n",
    "        \"Mean Training IoU\", \n",
    "        \"Validation IoU loss\", \n",
    "        \"Mean Validation IoU\"\n",
    "    ]\n",
    "    df = pd.DataFrame(records, columns=columns)\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    print(f\"  Metrics saved to {excel_path}\")\n",
    "\n",
    "    print(f\"Done training {model_name}.\\n\")\n",
    "\n",
    "    # Free up GPU memory after training this model\n",
    "    del model\n",
    "    gc.collect()  # Force garbage collection\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of models you want to train\n",
    "    models_to_train = {\n",
    "        \"Unet-DL\"   : UNet_DL,\n",
    "        \"Unet-JL\"   : UNet_JL,\n",
    "        \"Unet-FL\"   : UNet_FL,\n",
    "        \"Unet-TL\"   : UNet_TL,\n",
    "        \"Unet-LSL\"  : UNet_LSL,\n",
    "    }\n",
    "\n",
    "    for model_name, model_class in models_to_train.items():\n",
    "        train_and_evaluate_model(model_name, model_class, \n",
    "                                 train_loader, val_loader,\n",
    "                                 epochs=EPOCHS, patience=PATIENCE)\n",
    "        # Extra precaution: free any residual CUDA memory after each model training\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Prediction Images Of Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Turn off interactive backend (no pop-up windows)\n",
    "\n",
    "TEST_IMAGE_FOLDER       = 'CWD-3HSV/test/images'\n",
    "GROUND_TRUTH_MASK_FOLDER= 'CWD-3HSV/test/Morphed_Images'\n",
    "IMG_HEIGHT              = 640\n",
    "IMG_WIDTH               = 640\n",
    "NUM_CLASSES             = 3\n",
    "DEVICE                  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "def load_full_model(model_path):\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_ground_truth_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "\n",
    "def generate_segmentation_mask(model, image):\n",
    "    with torch.no_grad():\n",
    "        output = model(image)        # (B, NUM_CLASSES, H, W)\n",
    "        pred   = torch.argmax(output, dim=1)\n",
    "        return pred.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "def visualize_and_save_comparison(\n",
    "    model, input_image, gt_mask, class_rgb_mapping, input_image_path,\n",
    "    save_folder, save_predictions=True\n",
    "):\n",
    "    # Load the original image for visualization\n",
    "    original_image = Image.open(input_image_path).convert('RGB')\n",
    "    original_image = original_image.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    # Generate predicted mask\n",
    "    pred_mask = generate_segmentation_mask(model, input_image)\n",
    "\n",
    "    # Map predicted mask to RGB\n",
    "    rgb_pred_mask = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)\n",
    "    for class_id, rgb_value in class_rgb_mapping.items():\n",
    "        rgb_pred_mask[pred_mask == class_id] = rgb_value\n",
    "\n",
    "    # Map ground truth to RGB\n",
    "    rgb_gt_mask = np.zeros((gt_mask.shape[0], gt_mask.shape[1], 3), dtype=np.uint8)\n",
    "    for class_id, rgb_value in class_rgb_mapping.items():\n",
    "        rgb_gt_mask[gt_mask == class_id] = rgb_value\n",
    "\n",
    "    # Plot side-by-side\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(rgb_gt_mask)\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(rgb_pred_mask)\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the figure (no plt.show())\n",
    "    if save_predictions:\n",
    "        # For the figure\n",
    "        fig_filename = os.path.splitext(os.path.basename(input_image_path))[0] + '_compare.png'\n",
    "        fig_save_path= os.path.join(save_folder, fig_filename)\n",
    "        fig.savefig(fig_save_path, bbox_inches='tight')\n",
    "\n",
    "        # For the predicted mask alone\n",
    "        pred_mask_img = Image.fromarray(rgb_pred_mask)\n",
    "        pred_filename = os.path.splitext(os.path.basename(input_image_path))[0] + '_predmask.png'\n",
    "        pred_save_path= os.path.join(save_folder, pred_filename)\n",
    "        pred_mask_img.save(pred_save_path)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Class-to-RGB mapping\n",
    "# -------------------------------------------------------------------\n",
    "class_rgb_mapping = {\n",
    "    0: (0, 0, 0),    # black\n",
    "    1: (0, 255, 0),  # green\n",
    "    2: (255, 0, 0),  # red\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# MAIN: \n",
    "# 1) Find all \"Unet-...\" directories\n",
    "# 2) For each, load \"unet_best_model.pth\"\n",
    "# 3) Randomly pick 5 test images, generate predictions\n",
    "# 4) Save side-by-side figure + predicted mask\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Silence any console printing\n",
    "    # (Here we can reassign print to a no-op if needed)\n",
    "    def no_op(*args, **kwargs):\n",
    "        pass\n",
    "    print = no_op\n",
    "\n",
    "    # 1) Find directories that start with \"Unet-\"\n",
    "    all_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "    # 2) For each directory, load unet_best_model.pth\n",
    "    # and do random predictions\n",
    "    test_image_files = [\n",
    "        f for f in os.listdir(TEST_IMAGE_FOLDER)\n",
    "        if f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png')\n",
    "    ]\n",
    "    # If <5 images exist, use them all\n",
    "    if len(test_image_files) <= 5:\n",
    "        selected_images = test_image_files\n",
    "    else:\n",
    "        selected_images = random.sample(test_image_files, 5)\n",
    "\n",
    "    for model_dir in all_dirs:\n",
    "        model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "        if not os.path.isfile(model_path):\n",
    "            continue  # skip if no best model in that dir\n",
    "\n",
    "        # Create a subfolder \"Predictions\" inside model_dir\n",
    "        pred_save_folder = os.path.join(model_dir, \"Predictions\")\n",
    "        os.makedirs(pred_save_folder, exist_ok=True)\n",
    "\n",
    "        # Load model\n",
    "        model = load_full_model(model_path)\n",
    "\n",
    "        # For each selected image, compare\n",
    "        for image_file in selected_images:\n",
    "            input_image_path = os.path.join(TEST_IMAGE_FOLDER, image_file)\n",
    "            # ground truth\n",
    "            gt_mask_name = os.path.splitext(image_file)[0] + '_morphed.png'\n",
    "            gt_mask_path = os.path.join(GROUND_TRUTH_MASK_FOLDER, gt_mask_name)\n",
    "\n",
    "            input_image = preprocess_image(input_image_path)\n",
    "            ground_truth_mask = load_ground_truth_mask(gt_mask_path)\n",
    "\n",
    "            # Visualize and save\n",
    "            visualize_and_save_comparison(\n",
    "                model=model,\n",
    "                input_image=input_image,\n",
    "                gt_mask=ground_truth_mask,\n",
    "                class_rgb_mapping=class_rgb_mapping,\n",
    "                input_image_path=input_image_path,\n",
    "                save_folder=pred_save_folder,\n",
    "                save_predictions=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Turn off interactive display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "TEST_IMAGES_DIR = 'CWD-3HSV/test/images'\n",
    "TEST_MASKS_DIR  = 'CWD-3HSV/test/Morphed_Images'\n",
    "IMG_HEIGHT      = 640\n",
    "IMG_WIDTH       = 640\n",
    "NUM_CLASSES     = 3\n",
    "DEVICE          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Suppress console output\n",
    "def no_op(*args, **kwargs):\n",
    "    pass\n",
    "print = no_op  # Overwrite default print\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "def preprocess_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "\n",
    "def generate_predictions(model, image):\n",
    "    with torch.no_grad():\n",
    "        output = model(image)            # [B, NUM_CLASSES, H, W]\n",
    "        pred   = torch.argmax(output, 1) # pick class with max logit\n",
    "        return pred.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "def calculate_iou(pred_mask, gt_mask, num_classes):\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = np.logical_and(pred_mask == cls, gt_mask == cls).sum()\n",
    "        union        = np.logical_or(pred_mask == cls, gt_mask == cls).sum()\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        iou_per_class.append(iou)\n",
    "    return iou_per_class\n",
    "\n",
    "def calculate_dice(pred_mask, gt_mask, num_classes):\n",
    "    dice_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = np.logical_and(pred_mask == cls, gt_mask == cls).sum()\n",
    "        denom        = (np.sum(pred_mask == cls) + np.sum(gt_mask == cls))\n",
    "        dice         = 2.0 * intersection / denom if denom > 0 else 0\n",
    "        dice_per_class.append(dice)\n",
    "    return dice_per_class\n",
    "\n",
    "def calculate_jaccard(pred_mask, gt_mask, num_classes):\n",
    "    jaccard_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = np.logical_and(pred_mask == cls, gt_mask == cls).sum()\n",
    "        union        = np.logical_or(pred_mask == cls, gt_mask == cls).sum()\n",
    "        jaccard      = intersection / union if union > 0 else 0\n",
    "        jaccard_per_class.append(jaccard)\n",
    "    return jaccard_per_class\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, save_path, title=\"Confusion Matrix\", fmt='d'):\n",
    "    \"\"\"\n",
    "    'fmt': 'd' for counts, '.2f' for percentages\n",
    "    Saves the figure to 'save_path'.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_images_dir, test_masks_dir, num_classes, results_dir):\n",
    "    all_pred = []\n",
    "    all_gt   = []\n",
    "\n",
    "    iou_per_class       = np.zeros(num_classes)\n",
    "    dice_per_class      = np.zeros(num_classes)\n",
    "    jaccard_per_class   = np.zeros(num_classes)\n",
    "    accuracy_per_class  = np.zeros(num_classes)\n",
    "    precision_per_class = np.zeros(num_classes)\n",
    "    recall_per_class    = np.zeros(num_classes)\n",
    "    f1_per_class        = np.zeros(num_classes)\n",
    "\n",
    "    image_files  = [img for img in os.listdir(test_images_dir) if img.endswith('.jpg')]\n",
    "    total_samples= 0\n",
    "\n",
    "    for img_name in image_files:\n",
    "        image_path = os.path.join(test_images_dir, img_name)\n",
    "        mask_name  = img_name.replace('.jpg', '_morphed.png')\n",
    "        mask_path  = os.path.join(test_masks_dir, mask_name)\n",
    "\n",
    "        image   = preprocess_image(image_path)\n",
    "        gt_mask = preprocess_mask(mask_path)\n",
    "        pred_mask= generate_predictions(model, image)\n",
    "\n",
    "        # Flatten\n",
    "        all_pred.extend(pred_mask.flatten())\n",
    "        all_gt.extend(gt_mask.flatten())\n",
    "\n",
    "        # iou/dice/jaccard\n",
    "        iou_sample     = calculate_iou(pred_mask,     gt_mask, num_classes)\n",
    "        dice_sample    = calculate_dice(pred_mask,    gt_mask, num_classes)\n",
    "        jaccard_sample = calculate_jaccard(pred_mask, gt_mask, num_classes)\n",
    "\n",
    "        iou_per_class     += np.array(iou_sample)\n",
    "        dice_per_class    += np.array(dice_sample)\n",
    "        jaccard_per_class += np.array(jaccard_sample)\n",
    "\n",
    "        # per-class metrics\n",
    "        for cls in range(num_classes):\n",
    "            tp = np.sum((pred_mask == cls) & (gt_mask == cls))\n",
    "            fp = np.sum((pred_mask == cls) & (gt_mask != cls))\n",
    "            fn = np.sum((pred_mask != cls) & (gt_mask == cls))\n",
    "            total_class_pixels= np.sum(gt_mask == cls)\n",
    "            accuracy_per_class[cls] += tp / (total_class_pixels + 1e-6)\n",
    "\n",
    "            precision_per_class[cls]+= tp / (tp + fp + 1e-6)\n",
    "            recall_per_class[cls]   += tp / (tp + fn + 1e-6)\n",
    "            f1_per_class[cls]       += 2*tp / (2*tp + fp + fn + 1e-6)\n",
    "\n",
    "        total_samples += 1\n",
    "\n",
    "    # Normalize\n",
    "    accuracy_per_class  /= total_samples\n",
    "    precision_per_class /= total_samples\n",
    "    recall_per_class    /= total_samples\n",
    "    f1_per_class        /= total_samples\n",
    "    iou_per_class       /= total_samples\n",
    "    dice_per_class      /= total_samples\n",
    "    jaccard_per_class   /= total_samples\n",
    "\n",
    "    mean_dice     = np.mean(dice_per_class)\n",
    "    mean_jaccard  = np.mean(jaccard_per_class)\n",
    "\n",
    "    # freq weighted iou\n",
    "    all_gt_arr = np.array(all_gt)\n",
    "    class_counts= np.bincount(all_gt_arr, minlength=num_classes)\n",
    "    frequency_weighted_iou= np.average(iou_per_class, weights=class_counts)\n",
    "\n",
    "    # overall metrics\n",
    "    all_pred_arr = np.array(all_pred)\n",
    "    accuracy = (all_pred_arr == all_gt_arr).sum()/len(all_gt_arr)\n",
    "    precision= precision_score(all_gt_arr, all_pred_arr, average='weighted', zero_division=1)\n",
    "    recall   = recall_score(all_gt_arr,    all_pred_arr, average='weighted', zero_division=1)\n",
    "    f1       = f1_score(all_gt_arr,        all_pred_arr, average='weighted', zero_division=1)\n",
    "\n",
    "    mean_iou    = np.mean(iou_per_class)\n",
    "    weighted_iou= np.average(iou_per_class, weights=np.bincount(all_gt_arr))\n",
    "\n",
    "    # confusion matrix\n",
    "    confusion_matrix_counts= np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    for gt_val, pr_val in zip(all_gt_arr, all_pred_arr):\n",
    "        confusion_matrix_counts[gt_val, pr_val]+=1\n",
    "\n",
    "    confusion_matrix_percent= np.zeros_like(confusion_matrix_counts, dtype=float)\n",
    "    for r in range(num_classes):\n",
    "        row_sum = confusion_matrix_counts[r,:].sum()\n",
    "        if row_sum > 0:\n",
    "            confusion_matrix_percent[r,:] = (confusion_matrix_counts[r,:]/ row_sum)*100\n",
    "\n",
    "    class_names= [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "    # Save confusion matrices as PNG\n",
    "    cm_counts_path  = os.path.join(results_dir, \"Confusion_Matrix_Counts.png\")\n",
    "    cm_percent_path = os.path.join(results_dir, \"Confusion_Matrix_Percent.png\")\n",
    "    plot_confusion_matrix(confusion_matrix_counts,  class_names, save_path=cm_counts_path,  title=\"Confusion Matrix (Counts)\", fmt='d')\n",
    "    plot_confusion_matrix(confusion_matrix_percent, class_names, save_path=cm_percent_path, title=\"Confusion Matrix (Percent)\", fmt='.2f')\n",
    "\n",
    "    return (\n",
    "        accuracy, accuracy_per_class, precision, precision_per_class,\n",
    "        recall, recall_per_class, f1, f1_per_class,\n",
    "        iou_per_class, mean_iou, weighted_iou, frequency_weighted_iou,\n",
    "        dice_per_class, jaccard_per_class, mean_dice, mean_jaccard\n",
    "    )\n",
    "\n",
    "def save_results_to_excel(\n",
    "    model_name,\n",
    "    accuracy, accuracy_per_class,\n",
    "    precision, precision_per_class,\n",
    "    recall, recall_per_class,\n",
    "    f1, f1_per_class,\n",
    "    iou_per_class, mean_iou,\n",
    "    weighted_iou, frequency_weighted_iou,\n",
    "    dice_per_class, jaccard_per_class,\n",
    "    mean_dice, mean_jaccard,\n",
    "    save_directory\n",
    "):\n",
    "    # We'll store the final xlsx in the same directory as the model\n",
    "    excel_path = os.path.join(save_directory, \"Performance_Evaluation_Metrics.xlsx\")\n",
    "\n",
    "    columns = (\n",
    "        ['Model Name', 'Accuracy']\n",
    "        + [f'Accuracy Class {i}' for i in range(len(accuracy_per_class))]\n",
    "        + ['Precision'] + [f'Precision Class {i}' for i in range(len(precision_per_class))]\n",
    "        + ['Recall'] + [f'Recall Class {i}' for i in range(len(recall_per_class))]\n",
    "        + ['F1 Score'] + [f'F1 Score Class {i}' for i in range(len(f1_per_class))]\n",
    "        + [f'IoU Class {i}' for i in range(len(iou_per_class))]\n",
    "        + ['Mean IoU', 'Weighted IoU', 'Frequency Weighted IoU']\n",
    "        + [f'Dice Coefficient Class {i}' for i in range(len(dice_per_class))]\n",
    "        + ['Mean Dice']\n",
    "        + [f'Jaccard Index Class {i}' for i in range(len(jaccard_per_class))]\n",
    "        + ['Mean Jaccard']\n",
    "    )\n",
    "\n",
    "    new_row = {\n",
    "        'Model Name': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        **{f'Accuracy Class {i}': acc for i, acc in enumerate(accuracy_per_class)},\n",
    "        'Precision': precision,\n",
    "        **{f'Precision Class {i}': prec for i, prec in enumerate(precision_per_class)},\n",
    "        'Recall': recall,\n",
    "        **{f'Recall Class {i}': r for i, r in enumerate(recall_per_class)},\n",
    "        'F1 Score': f1,\n",
    "        **{f'F1 Score Class {i}': f1c for i, f1c in enumerate(f1_per_class)},\n",
    "        **{f'IoU Class {i}': iou for i, iou in enumerate(iou_per_class)},\n",
    "        'Mean IoU': mean_iou,\n",
    "        'Weighted IoU': weighted_iou,\n",
    "        'Frequency Weighted IoU': frequency_weighted_iou,\n",
    "        **{f'Dice Coefficient Class {i}': d for i, d in enumerate(dice_per_class)},\n",
    "        'Mean Dice': mean_dice,\n",
    "        **{f'Jaccard Index Class {i}': j for i, j in enumerate(jaccard_per_class)},\n",
    "        'Mean Jaccard': mean_jaccard,\n",
    "    }\n",
    "\n",
    "    new_data = pd.DataFrame([new_row], columns=columns)\n",
    "\n",
    "    # Overwrite any existing file to store only the last row\n",
    "    new_data.to_excel(excel_path, index=False, header=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppress console output\n",
    "    def no_op(*args, **kwargs):\n",
    "        pass\n",
    "    print = no_op  # Overwrite default print\n",
    "\n",
    "    # 1) Find all directories that match \"Unet-<backbone>\"\n",
    "    all_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "    for model_dir in all_dirs:\n",
    "        # 2) Load \"unet_best_model.pth\" in that directory, if exists\n",
    "        model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "        if not os.path.isfile(model_path):\n",
    "            continue  # skip if no best model found\n",
    "\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # 3) Evaluate\n",
    "        results = evaluate_model(\n",
    "            model=model,\n",
    "            test_images_dir=TEST_IMAGES_DIR,\n",
    "            test_masks_dir=TEST_MASKS_DIR,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            results_dir=model_dir  # store confusion matrix PNG in same directory\n",
    "        )\n",
    "\n",
    "        # 4) Unpack\n",
    "        (\n",
    "            accuracy, accuracy_per_class,\n",
    "            precision, precision_per_class,\n",
    "            recall, recall_per_class,\n",
    "            f1, f1_per_class,\n",
    "            iou_per_class, mean_iou,\n",
    "            weighted_iou, frequency_weighted_iou,\n",
    "            dice_per_class, jaccard_per_class,\n",
    "            mean_dice, mean_jaccard\n",
    "        ) = results\n",
    "\n",
    "        # 5) Save row to \"Performance_Evaluation_Metrics.xlsx\" in model_dir\n",
    "        save_results_to_excel(\n",
    "            model_name=model_dir,\n",
    "            accuracy=accuracy,\n",
    "            accuracy_per_class=accuracy_per_class,\n",
    "            precision=precision,\n",
    "            precision_per_class=precision_per_class,\n",
    "            recall=recall,\n",
    "            recall_per_class=recall_per_class,\n",
    "            f1=f1,\n",
    "            f1_per_class=f1_per_class,\n",
    "            iou_per_class=iou_per_class,\n",
    "            mean_iou=mean_iou,\n",
    "            weighted_iou=weighted_iou,\n",
    "            frequency_weighted_iou=frequency_weighted_iou,\n",
    "            dice_per_class=dice_per_class,\n",
    "            jaccard_per_class=jaccard_per_class,\n",
    "            mean_dice=mean_dice,\n",
    "            mean_jaccard=mean_jaccard,\n",
    "            save_directory=model_dir\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Training Curves Of Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # So figures don't pop up; they are just saved\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves_for_model(excel_path, output_dir):\n",
    "    \"\"\"\n",
    "    Reads Training_Metrics.xlsx from excel_path and saves four plots in output_dir.\n",
    "    \"\"\"\n",
    "    # Read Excel\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    # Extract columns\n",
    "    epochs            = df['Epoch']\n",
    "    train_loss        = df['Training Loss']\n",
    "    val_loss          = df['Validation Loss']\n",
    "    train_acc         = df['Training Accuracy']\n",
    "    val_acc           = df['Validation Accuracy']\n",
    "    train_iou_loss    = df['Training IoU loss']\n",
    "    val_iou_loss      = df['Validation IoU loss']\n",
    "    mean_train_iou    = df['Mean Training IoU']\n",
    "    mean_val_iou      = df['Mean Validation IoU']\n",
    "\n",
    "    # 1) Training vs Validation Loss\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, train_loss, label='Training Loss', marker='o')\n",
    "    plt.plot(epochs, val_loss,   label='Validation Loss', marker='s')\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    loss_plot_path = os.path.join(output_dir, 'Train_vs_Val_Loss.png')\n",
    "    plt.savefig(loss_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 2) Training vs Validation Accuracy\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, train_acc, label='Training Accuracy', marker='o')\n",
    "    plt.plot(epochs, val_acc,   label='Validation Accuracy', marker='s')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    acc_plot_path = os.path.join(output_dir, 'Train_vs_Val_Accuracy.png')\n",
    "    plt.savefig(acc_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 3) Training IoU Loss vs Validation IoU Loss\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, train_iou_loss, label='Training IoU Loss', marker='o')\n",
    "    plt.plot(epochs, val_iou_loss,   label='Validation IoU Loss', marker='s')\n",
    "    plt.title('Training vs Validation IoU Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    iou_loss_plot_path = os.path.join(output_dir, 'Train_vs_Val_IoU_Loss.png')\n",
    "    plt.savefig(iou_loss_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 4) Mean Training IoU vs Mean Validation IoU\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, mean_train_iou, label='Mean Training IoU', marker='o')\n",
    "    plt.plot(epochs, mean_val_iou,   label='Mean Validation IoU', marker='s')\n",
    "    plt.title('Mean Training IoU vs Mean Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    iou_plot_path = os.path.join(output_dir, 'Mean_Train_vs_Val_IoU.png')\n",
    "    plt.savefig(iou_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # 1) Find directories named \"Unet-...\"\n",
    "    unet_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith('Unet')]\n",
    "\n",
    "    for unet_dir in unet_dirs:\n",
    "        # 2) The path to the Training_Metrics.xlsx\n",
    "        excel_path = os.path.join(unet_dir, 'Training_Metrics.xlsx')\n",
    "        if not os.path.isfile(excel_path):\n",
    "            continue  # skip if no metrics file\n",
    "\n",
    "        # 3) Create \"Training_Curves\" subdir\n",
    "        curves_dir = os.path.join(unet_dir, 'Training_Curves')\n",
    "        os.makedirs(curves_dir, exist_ok=True)\n",
    "\n",
    "        # 4) Generate + save plots\n",
    "        plot_training_curves_for_model(excel_path, curves_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models Performance Evaluation Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Automatically discover directories named \"Unet-...\"\n",
    "model_directories = [\n",
    "    d for d in os.listdir('.') \n",
    "    if os.path.isdir(d) and d.startswith(\"Unet\")\n",
    "]\n",
    "\n",
    "# 2) Each directory's Excel file name\n",
    "excel_filename = \"Performance_Evaluation_Metrics.xlsx\"\n",
    "\n",
    "# 3) Where to save the merged file\n",
    "results_folder = \"Results\"\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "merged_excel_path = os.path.join(results_folder, \"All_Models_Performance_Evaluation_Metrics.xlsx\")\n",
    "\n",
    "# 4) Create an empty list to hold the last rows from each subdirectory\n",
    "merged_rows = []\n",
    "\n",
    "# 5) Loop over each Unet-<backbone> directory\n",
    "for model_dir in model_directories:\n",
    "    excel_path = os.path.join(model_dir, excel_filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(excel_path):\n",
    "        print(f\"Warning: {excel_path} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Read entire Excel file\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"Warning: {excel_path} is empty. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Get the last (bottom) row\n",
    "    last_row = df.iloc[[-1]].copy()\n",
    "    merged_rows.append(last_row)\n",
    "\n",
    "# 6) If we have rows, concatenate them; otherwise create empty DataFrame\n",
    "if len(merged_rows) > 0:\n",
    "    merged_df = pd.concat(merged_rows, ignore_index=True)\n",
    "else:\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "# 7) Overwrite the final Excel file with these rows\n",
    "merged_df.to_excel(merged_excel_path, index=False)\n",
    "print(f\"Merged file saved to: {merged_excel_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Predictions For All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Automatically gather all directories starting with \"Unet-\"\n",
    "# ------------------------------------------------------------------------------\n",
    "all_dirs = [d for d in os.listdir('.') if os.path.isdir(d)]\n",
    "model_dirs = [d for d in all_dirs if d.startswith(\"Unet-\")]\n",
    "models_info = [(d, os.path.join(d, \"unet_best_model.pth\")) for d in model_dirs]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Define directories / file paths and hyperparameters\n",
    "# ------------------------------------------------------------------------------\n",
    "TEST_IMAGE_FOLDER        = 'CWD-3HSV/test/images/'\n",
    "GROUND_TRUTH_MASK_FOLDER = 'CWD-3HSV/test/Morphed_Images/'\n",
    "PREDICTION_SAVE_FOLDER   = 'Predictions'\n",
    "os.makedirs(PREDICTION_SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "IMG_HEIGHT  = 640\n",
    "IMG_WIDTH   = 640\n",
    "NUM_CLASSES = 3\n",
    "DEVICE      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Define transformation (as used during training)\n",
    "# ------------------------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Helper functions\n",
    "# ------------------------------------------------------------------------------\n",
    "def load_full_model(model_path):\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    return image\n",
    "\n",
    "def load_ground_truth_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "def generate_segmentation_mask(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)  # shape: (B, NUM_CLASSES, H, W)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        return pred.squeeze().cpu().numpy()  # shape: (H, W)\n",
    "\n",
    "def mask_to_rgb(mask_array):\n",
    "    h, w = mask_array.shape\n",
    "    rgb_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    # Define the mapping for 3 classes\n",
    "    class_rgb_mapping = {\n",
    "        0: (0, 0, 0),      # Black for background (or class 0)\n",
    "        1: (0, 255, 0),    # Green for class 1\n",
    "        2: (255, 0, 0)     # Red for class 2\n",
    "    }\n",
    "    for cls, color in class_rgb_mapping.items():\n",
    "        rgb_image[mask_array == cls] = color\n",
    "    return rgb_image\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) Main execution: load models, select images, and create merged figure\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load all models\n",
    "    loaded_models = []\n",
    "    for model_name, model_path in models_info:\n",
    "        if not os.path.isfile(model_path):\n",
    "            continue\n",
    "        model = load_full_model(model_path)\n",
    "        loaded_models.append((model_name, model))\n",
    "    if len(loaded_models) == 0:\n",
    "        exit(0)\n",
    "    \n",
    "    # Gather test images\n",
    "    test_image_files = [f for f in os.listdir(TEST_IMAGE_FOLDER) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "    if len(test_image_files) == 0:\n",
    "        exit(0)\n",
    "    \n",
    "    # Randomly select up to 5 images\n",
    "    selected_images = random.sample(test_image_files, 5) if len(test_image_files) >= 5 else test_image_files\n",
    "\n",
    "    # Set up figure:\n",
    "    n_rows = len(selected_images)\n",
    "    n_cols = 2 + len(loaded_models)  # 1: Input, 1: GT, rest: each model's prediction\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 4.2 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes]  # ensure axes is a list of rows\n",
    "\n",
    "    # Process each image:\n",
    "    for row_idx, image_file in enumerate(selected_images):\n",
    "        input_image_path = os.path.join(TEST_IMAGE_FOLDER, image_file)\n",
    "        gt_mask_name = os.path.splitext(image_file)[0] + '_morphed.png'\n",
    "        gt_mask_path = os.path.join(GROUND_TRUTH_MASK_FOLDER, gt_mask_name)\n",
    "\n",
    "        # Load and resize input image and ground truth mask for display\n",
    "        original_image = Image.open(input_image_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        gt_mask_np = load_ground_truth_mask(gt_mask_path)\n",
    "        gt_rgb = mask_to_rgb(gt_mask_np)\n",
    "\n",
    "        # Preprocess image for model inference\n",
    "        input_tensor = preprocess_image(input_image_path)\n",
    "\n",
    "        # Column 0: Input image\n",
    "        axes[row_idx][0].imshow(original_image)\n",
    "        if row_idx == 0:\n",
    "            axes[row_idx][0].set_title(\"Input Image\", fontsize=27)\n",
    "        axes[row_idx][0].axis('off')\n",
    "\n",
    "        # Column 1: Ground truth mask\n",
    "        axes[row_idx][1].imshow(gt_rgb)\n",
    "        if row_idx == 0:\n",
    "            axes[row_idx][1].set_title(\"Ground Truth Mask\", fontsize=27)\n",
    "        axes[row_idx][1].axis('off')\n",
    "\n",
    "        # Next columns: Predictions from each model\n",
    "        for model_i, (model_name, model_obj) in enumerate(loaded_models):\n",
    "            pred_mask = generate_segmentation_mask(model_obj, input_tensor)\n",
    "            pred_rgb = mask_to_rgb(pred_mask)\n",
    "            col_idx = 2 + model_i\n",
    "            axes[row_idx][col_idx].imshow(pred_rgb)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][col_idx].set_title(f\"{model_name} \\nPredicted Mask\", fontsize=27)\n",
    "            axes[row_idx][col_idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    merged_filename = os.path.join(PREDICTION_SAVE_FOLDER, \"All_Models_Predictions.png\")\n",
    "    plt.savefig(merged_filename, bbox_inches='tight',dpi=200)\n",
    "    # Uncomment the next line if you wish to display the figure interactively\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Predictions of Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Automatically gather all directories starting with \"Unet-\"\n",
    "# ------------------------------------------------------------------------------\n",
    "model_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Define directories and hyperparameters\n",
    "# ------------------------------------------------------------------------------\n",
    "TEST_IMAGE_FOLDER        = 'CWD-3HSV/test/images/'\n",
    "GROUND_TRUTH_MASK_FOLDER = 'CWD-3HSV/test/Morphed_Images/'\n",
    "# (The merged prediction figure for each model will be saved in a \"Predictions\" subfolder of that model directory.)\n",
    "IMG_HEIGHT  = 640\n",
    "IMG_WIDTH   = 640\n",
    "NUM_CLASSES = 3\n",
    "DEVICE      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Define the transformation (as used during training)\n",
    "# ------------------------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Helper functions\n",
    "# ------------------------------------------------------------------------------\n",
    "def load_full_model(model_dir):\n",
    "    \"\"\"Load the full model from <model_dir>/unet_best_model.pth.\"\"\"\n",
    "    model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "    if not os.path.isfile(model_path):\n",
    "        return None\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    return image\n",
    "\n",
    "def load_ground_truth_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "def generate_segmentation_mask(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        # model outputs logits of shape (B, NUM_CLASSES, H, W)\n",
    "        output = model(image_tensor)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        return pred.squeeze().cpu().numpy()  # shape: (H, W)\n",
    "\n",
    "def mask_to_rgb(mask_array):\n",
    "    h, w = mask_array.shape\n",
    "    rgb_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    # Fixed mapping for 3 classes\n",
    "    class_rgb_mapping = {\n",
    "        0: (0, 0, 0),      # Black\n",
    "        1: (0, 255, 0),    # Green\n",
    "        2: (255, 0, 0)     # Red\n",
    "    }\n",
    "    for cls, color in class_rgb_mapping.items():\n",
    "        rgb_image[mask_array == cls] = color\n",
    "    return rgb_image\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) Main execution: Process each model directory\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Gather test images (all jpg/jpeg/png)\n",
    "    test_image_files = [f for f in os.listdir(TEST_IMAGE_FOLDER) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "    if len(test_image_files) == 0:\n",
    "        exit(0)\n",
    "    \n",
    "    # Randomly select up to 5 images\n",
    "    selected_images = random.sample(test_image_files, 5) if len(test_image_files) >= 5 else test_image_files\n",
    "\n",
    "    # Process each model directory that starts with \"Unet-\"\n",
    "    for model_dir in model_dirs:\n",
    "        model = load_full_model(model_dir)\n",
    "        if model is None:\n",
    "            continue\n",
    "        \n",
    "        # Create a Predictions subfolder inside the model directory\n",
    "        predictions_dir = os.path.join(model_dir, \"Predictions\")\n",
    "        os.makedirs(predictions_dir, exist_ok=True)\n",
    "        \n",
    "        # Set up a figure with one row per image and 3 columns (Input, Ground Truth, Predicted)\n",
    "        n_rows = len(selected_images)\n",
    "        n_cols = 3\n",
    "        fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(4 * n_cols, 4.2 * n_rows))\n",
    "        if n_rows == 1:\n",
    "            axes = [axes]  # Ensure axes is a list of rows\n",
    "\n",
    "        for row_idx, image_file in enumerate(selected_images):\n",
    "            input_image_path = os.path.join(TEST_IMAGE_FOLDER, image_file)\n",
    "            gt_mask_name = os.path.splitext(image_file)[0] + '_morphed.png'\n",
    "            gt_mask_path = os.path.join(GROUND_TRUTH_MASK_FOLDER, gt_mask_name)\n",
    "            \n",
    "            # Load original image and ground truth for display\n",
    "            original_image = Image.open(input_image_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "            gt_mask_np = load_ground_truth_mask(gt_mask_path)\n",
    "            gt_rgb = mask_to_rgb(gt_mask_np)\n",
    "            \n",
    "            # Preprocess image for inference\n",
    "            input_tensor = preprocess_image(input_image_path)\n",
    "            \n",
    "            # Column 0: Input image\n",
    "            axes[row_idx][0].imshow(original_image)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][0].set_title(\"Input Image\", fontsize=27)\n",
    "            axes[row_idx][0].axis('off')\n",
    "            \n",
    "            # Column 1: Ground truth mask\n",
    "            axes[row_idx][1].imshow(gt_rgb)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][1].set_title(\"Ground Truth Mask\", fontsize=27)\n",
    "            axes[row_idx][1].axis('off')\n",
    "            \n",
    "            # Column 2: Predicted mask from this model\n",
    "            pred_mask = generate_segmentation_mask(model, input_tensor)\n",
    "            pred_rgb = mask_to_rgb(pred_mask)\n",
    "            axes[row_idx][2].imshow(pred_rgb)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][2].set_title(f\"{model_dir} \\nPredicted Mask\", fontsize=27)\n",
    "            axes[row_idx][2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        merged_filename = os.path.join(predictions_dir, \"All_Models_Predictions.png\")\n",
    "        # Save the figure at high resolution\n",
    "        plt.savefig(merged_filename, bbox_inches='tight', dpi=300)\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Automatically gather all directories starting with \"Unet-\"\n",
    "# ------------------------------------------------------------------------------\n",
    "model_directories = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "# Name of the Excel file in each model directory\n",
    "excel_filename = \"Performance_Evaluation_Metrics.xlsx\"\n",
    "\n",
    "# Loop over each found model directory\n",
    "for model_dir in model_directories:\n",
    "    # Construct the full path to the Excel file\n",
    "    excel_path = os.path.join(model_dir, excel_filename)\n",
    "    \n",
    "    # Skip this directory if the file does not exist\n",
    "    if not os.path.isfile(excel_path):\n",
    "        continue\n",
    "    \n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(excel_path)\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    # Get the last (bottom) row from the DataFrame\n",
    "    last_row = df.iloc[-1]\n",
    "    \n",
    "    # ------------------ Overall Metrics ------------------\n",
    "    overall_metrics = {\n",
    "        \"Metric\": [\n",
    "            \"Accuracy\",\n",
    "            \"Precision\",\n",
    "            \"Recall\",\n",
    "            \"F1 Score\",\n",
    "            \"Mean IoU\",\n",
    "            \"Frequency Weighted IoU\",\n",
    "            \"Mean Dice\",\n",
    "            \"Mean Jaccard\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            last_row[\"Accuracy\"],\n",
    "            last_row[\"Precision\"],\n",
    "            last_row[\"Recall\"],\n",
    "            last_row[\"F1 Score\"],\n",
    "            last_row[\"Mean IoU\"],\n",
    "            last_row[\"Frequency Weighted IoU\"],\n",
    "            last_row[\"Mean Dice\"],\n",
    "            last_row[\"Mean Jaccard\"]\n",
    "        ]\n",
    "    }\n",
    "    overall_df = pd.DataFrame(overall_metrics)\n",
    "    \n",
    "    # ------------------ Per-Class Metrics ------------------\n",
    "    per_class_data = {\n",
    "        \"Class\": [\"Class 0\", \"Class 1\", \"Class 2\"],\n",
    "        \"Accuracy\": [\n",
    "            last_row[\"Accuracy Class 0\"],\n",
    "            last_row[\"Accuracy Class 1\"],\n",
    "            last_row[\"Accuracy Class 2\"]\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            last_row[\"Precision Class 0\"],\n",
    "            last_row[\"Precision Class 1\"],\n",
    "            last_row[\"Precision Class 2\"]\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            last_row[\"Recall Class 0\"],\n",
    "            last_row[\"Recall Class 1\"],\n",
    "            last_row[\"Recall Class 2\"]\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            last_row[\"F1 Score Class 0\"],\n",
    "            last_row[\"F1 Score Class 1\"],\n",
    "            last_row[\"F1 Score Class 2\"]\n",
    "        ],\n",
    "        \"IoU\": [\n",
    "            last_row[\"IoU Class 0\"],\n",
    "            last_row[\"IoU Class 1\"],\n",
    "            last_row[\"IoU Class 2\"]\n",
    "        ],\n",
    "        \"Dice\": [\n",
    "            last_row[\"Dice Coefficient Class 0\"],\n",
    "            last_row[\"Dice Coefficient Class 1\"],\n",
    "            last_row[\"Dice Coefficient Class 2\"]\n",
    "        ],\n",
    "        \"Jaccard\": [\n",
    "            last_row[\"Jaccard Index Class 0\"],\n",
    "            last_row[\"Jaccard Index Class 1\"],\n",
    "            last_row[\"Jaccard Index Class 2\"]\n",
    "        ]\n",
    "    }\n",
    "    per_class_df = pd.DataFrame(per_class_data)\n",
    "    \n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 3) Save the new Excel files in a Results subfolder of the model directory\n",
    "    # ------------------------------------------------------------------------------\n",
    "    results_dir = os.path.join(model_dir, \"Results\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    overall_excel_path = os.path.join(results_dir, \"Overall_Metrics.xlsx\")\n",
    "    per_class_excel_path = os.path.join(results_dir, \"Per_Class_Metrics.xlsx\")\n",
    "    \n",
    "    overall_df.to_excel(overall_excel_path, index=False)\n",
    "    per_class_df.to_excel(per_class_excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating All Models Perdormance Evaluation Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Path to the merged Excel file\n",
    "# ------------------------------------------------------------------------------\n",
    "merged_excel_path = os.path.join(\"Results\", \"All_Models_Performance_Evaluation_Metrics.xlsx\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Read the Excel file into a DataFrame\n",
    "# ------------------------------------------------------------------------------\n",
    "df = pd.read_excel(merged_excel_path)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Mapping to change model names\n",
    "# ------------------------------------------------------------------------------\n",
    "name_mapping = {\n",
    "    \"unet_best_model.pth\": \"Unet\",\n",
    "    \"unetplusplus_best_model.pth\": \"Unet++\",\n",
    "    \"manet_best_model.pth\": \"MAnet\",\n",
    "    \"linknet_best_model.pth\": \"Linknet\",\n",
    "    \"fpn_best_model.pth\": \"FPN\",\n",
    "    \"pspnet_best_model.pth\": \"PSPNet\",\n",
    "    \"pan_best_model.pth\": \"PAN\",\n",
    "    \"deeplabv3_best_model.pth\": \"DeepLabV3\",\n",
    "    \"deeplabv3plus_best_model.pth\": \"DeepLabV3+\",\n",
    "    \"upernet_best_model.pth\": \"UPerNet\",\n",
    "    \"segformer_best_model.pth\": \"Segformer\"\n",
    "}\n",
    "\n",
    "# Update the \"Model Name\" column based on the mapping.\n",
    "# If a model name is not found in the mapping, leave it unchanged.\n",
    "df[\"Model Name\"] = df[\"Model Name\"].apply(lambda x: name_mapping.get(x, x))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Create Overall Metrics DataFrame\n",
    "# ------------------------------------------------------------------------------\n",
    "overall_columns = [\n",
    "    \"Model Name\",\n",
    "    \"Accuracy\",\n",
    "    \"Precision\",\n",
    "    \"Recall\",\n",
    "    \"F1 Score\",\n",
    "    \"Mean IoU\",\n",
    "    \"Weighted IoU\",\n",
    "    \"Frequency Weighted IoU\",\n",
    "    \"Mean Dice\",\n",
    "    \"Mean Jaccard\"\n",
    "]\n",
    "overall_df = df[overall_columns].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) Create Per-Class Metrics DataFrame\n",
    "# ------------------------------------------------------------------------------\n",
    "per_class_columns = [\n",
    "    \"Model Name\",\n",
    "    \"Accuracy Class 0\", \"Accuracy Class 1\", \"Accuracy Class 2\",\n",
    "    \"Precision Class 0\", \"Precision Class 1\", \"Precision Class 2\",\n",
    "    \"Recall Class 0\", \"Recall Class 1\", \"Recall Class 2\",\n",
    "    \"F1 Score Class 0\", \"F1 Score Class 1\", \"F1 Score Class 2\",\n",
    "    \"IoU Class 0\", \"IoU Class 1\", \"IoU Class 2\",\n",
    "    \"Dice Coefficient Class 0\", \"Dice Coefficient Class 1\", \"Dice Coefficient Class 2\",\n",
    "    \"Jaccard Index Class 0\", \"Jaccard Index Class 1\", \"Jaccard Index Class 2\"\n",
    "]\n",
    "per_class_df = df[per_class_columns].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6) Save the two DataFrames to Excel (overwrite if re-executed)\n",
    "# ------------------------------------------------------------------------------\n",
    "overall_excel_path = os.path.join(\"Results\", \"Overall_Metrics.xlsx\")\n",
    "per_class_excel_path = os.path.join(\"Results\", \"Per_Class_Metrics.xlsx\")\n",
    "\n",
    "overall_df.to_excel(overall_excel_path, index=False)\n",
    "per_class_df.to_excel(per_class_excel_path, index=False)\n",
    "\n",
    "print(f\"Saved overall metrics to: {overall_excel_path}\")\n",
    "print(f\"Saved per-class metrics to: {per_class_excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
