{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc1 = self.enc1(x)                      # (B,64,H,W)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))   # (B,128,H/2,W/2)\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))   # (B,256,H/4,W/4)\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))   # (B,512,H/8,W/8)\n",
    "\n",
    "        # ---------------- Bridge ----------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B,1024,H/16,W/16)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                    # (B,512,H/8,W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)      # (B,1024,H/8,W/8)\n",
    "        dec4 = self.dec4(dec4)                     # (B,512,H/8,W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                      # (B,256,H/4,W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)      # (B,512,H/4,W/4)\n",
    "        dec3 = self.dec3(dec3)                     # (B,256,H/4,W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                      # (B,128,H/2,W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)      # (B,256,H/2,W/2)\n",
    "        dec2 = self.dec2(dec2)                     # (B,128,H/2,W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                      # (B,64,H,W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)      # (B,128,H,W)\n",
    "        dec1 = self.dec1(dec1)                     # (B,64,H,W)\n",
    "\n",
    "        # Output\n",
    "        out = self.out(dec1)                       # (B,out_channels,H,W)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet_BN(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_BN, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"(Conv -> BN -> ReLU) Ã— 2 block.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc1 = self.enc1(x)                      # (B,64,H,W)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))   # (B,128,H/2,W/2)\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))   # (B,256,H/4,W/4)\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))   # (B,512,H/8,W/8)\n",
    "\n",
    "        # ---------------- Bridge ----------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B,1024,H/16,W/16)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                    # (B,512,H/8,W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)      # (B,1024,H/8,W/8)\n",
    "        dec4 = self.dec4(dec4)                     # (B,512,H/8,W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                      # (B,256,H/4,W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)      # (B,512,H/4,W/4)\n",
    "        dec3 = self.dec3(dec3)                     # (B,256,H/4,W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                      # (B,128,H/2,W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)      # (B,256,H/2,W/2)\n",
    "        dec2 = self.dec2(dec2)                     # (B,128,H/2,W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                      # (B,64,H,W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)      # (B,128,H,W)\n",
    "        dec1 = self.dec1(dec1)                     # (B,64,H,W)\n",
    "\n",
    "        # Output\n",
    "        out = self.out(dec1)                       # (B,out_channels,H,W)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet With Spatial Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel-wise average pooling\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        # Channel-wise max pooling\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "\n",
    "        # Concatenate along channel dimension\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "\n",
    "        # Convolve, then apply sigmoid -> attention mask\n",
    "        attn = self.conv1(out)\n",
    "        attn = self.sigmoid(attn)\n",
    "\n",
    "        # Multiply the attention mask with the input\n",
    "        return x * attn\n",
    "\n",
    "class UNet_SA(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_SA, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "        # Spatial Attention modules\n",
    "        self.sa1 = SpatialAttention()\n",
    "        self.sa2 = SpatialAttention()\n",
    "        self.sa3 = SpatialAttention()\n",
    "        self.sa4 = SpatialAttention()\n",
    "        self.sa_bridge = SpatialAttention()\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        A basic (Conv -> ReLU -> Conv -> ReLU) block,\n",
    "        no Batch Normalization layers.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ------------------ Encoder ------------------\n",
    "        enc1 = self.enc1(x)            # (B,64,H,W)\n",
    "        enc1 = self.sa1(enc1)          # Spatial attention\n",
    "\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))  # (B,128,H/2,W/2)\n",
    "        enc2 = self.sa2(enc2)\n",
    "\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))  # (B,256,H/4,W/4)\n",
    "        enc3 = self.sa3(enc3)\n",
    "\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))  # (B,512,H/8,W/8)\n",
    "        enc4 = self.sa4(enc4)\n",
    "\n",
    "        # ------------------ Bridge -------------------\n",
    "        bridge = self.bridge(F.max_pool2d(enc4, 2))  # (B,1024,H/16,W/16)\n",
    "        bridge = self.sa_bridge(bridge)\n",
    "\n",
    "        # ------------------ Decoder ------------------\n",
    "        # Up4\n",
    "        dec4 = self.up4(bridge)                 # (B,512,H/8,W/8)\n",
    "        dec4 = torch.cat([enc4, dec4], dim=1)   # (B,1024,H/8,W/8)\n",
    "        dec4 = self.dec4(dec4)                  # (B,512,H/8,W/8)\n",
    "\n",
    "        # Up3\n",
    "        dec3 = self.up3(dec4)                   # (B,256,H/4,W/4)\n",
    "        dec3 = torch.cat([enc3, dec3], dim=1)   # (B,512,H/4,W/4)\n",
    "        dec3 = self.dec3(dec3)                  # (B,256,H/4,W/4)\n",
    "\n",
    "        # Up2\n",
    "        dec2 = self.up2(dec3)                   # (B,128,H/2,W/2)\n",
    "        dec2 = torch.cat([enc2, dec2], dim=1)   # (B,256,H/2,W/2)\n",
    "        dec2 = self.dec2(dec2)                  # (B,128,H/2,W/2)\n",
    "\n",
    "        # Up1\n",
    "        dec1 = self.up1(dec2)                   # (B,64,H,W)\n",
    "        dec1 = torch.cat([enc1, dec1], dim=1)   # (B,128,H,W)\n",
    "        dec1 = self.dec1(dec1)                  # (B,64,H,W)\n",
    "\n",
    "        # Final conv\n",
    "        out = self.out(dec1)                    # (B,out_channels,H,W)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet with dense skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet_DSC(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_DSC, self).__init__()        \n",
    "        self.enc1 = self.conv_block(in_channels, 64)    \n",
    "        self.enc2 = self.conv_block(64, 128)            \n",
    "        self.enc3 = self.conv_block(128, 256)           \n",
    "        self.enc4 = self.conv_block(256, 512)           \n",
    "        self.bridge = self.conv_block(512, 1024)        \n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)  \n",
    "        self.dec4 = self.conv_block(512+512+256+128+64, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)   \n",
    "        self.dec3 = self.conv_block(256+256+128+64, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)   \n",
    "        self.dec2 = self.conv_block(128+128+64, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)           \n",
    "        self.dec1 = self.conv_block(64+64, 64)     \n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Two successive (Conv -> ReLU) layers (no batch normalization).\n",
    "        Adjust if you want BN or other features.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,H,W = x.shape\n",
    "        enc1 = self.enc1(x)      \n",
    "        e2_in= F.max_pool2d(enc1, 2)\n",
    "        enc2 = self.enc2(e2_in)     \n",
    "        e3_in= F.max_pool2d(enc2, 2)\n",
    "        enc3 = self.enc3(e3_in)      \n",
    "        e4_in= F.max_pool2d(enc3, 2)\n",
    "        enc4 = self.enc4(e4_in)    \n",
    "        b_in = F.max_pool2d(enc4, 2)\n",
    "        bridge = self.bridge(b_in)\n",
    "        dec4_up = self.up4(bridge)        \n",
    "        enc1_8 = F.interpolate(enc1, scale_factor=1/8, mode='bilinear', align_corners=False)  \n",
    "        enc2_8 = F.interpolate(enc2, scale_factor=1/4, mode='bilinear', align_corners=False)  \n",
    "        enc3_8 = F.interpolate(enc3, scale_factor=1/2, mode='bilinear', align_corners=False)        \n",
    "        dec4_in = torch.cat([dec4_up, enc4, enc3_8, enc2_8, enc1_8], dim=1)\n",
    "        dec4 = self.dec4(dec4_in)           \n",
    "        dec3_up = self.up3(dec4)          \n",
    "        enc1_4 = F.interpolate(enc1, scale_factor=1/4, mode='bilinear', align_corners=False)  \n",
    "        enc2_4 = F.interpolate(enc2, scale_factor=1/2, mode='bilinear', align_corners=False)        \n",
    "        dec3_in= torch.cat([dec3_up, enc3, enc2_4, enc1_4], dim=1)\n",
    "        dec3   = self.dec3(dec3_in)              \n",
    "        dec2_up= self.up2(dec3)           \n",
    "        enc1_2 = F.interpolate(enc1, scale_factor=1/2, mode='bilinear', align_corners=False)       \n",
    "        dec2_in= torch.cat([dec2_up, enc2, enc1_2], dim=1)\n",
    "        dec2   = self.dec2(dec2_in)              \n",
    "        dec1_up= self.up1(dec2)                 \n",
    "        dec1_in= torch.cat([dec1_up, enc1], dim=1)  \n",
    "        dec1   = self.dec1(dec1_in)       \n",
    "        out = self.out(dec1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet With Spatial Attention + Batch Normalization + Dense Skip Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size,\n",
    "                              padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        # Channel-wise avg\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B,1,H,W)\n",
    "        # Channel-wise max\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)# (B,1,H,W)\n",
    "        # cat => (B,2,H,W)\n",
    "        attn_in = torch.cat([avg_out, max_out], dim=1)\n",
    "        attn    = self.conv(attn_in)     # (B,1,H,W)\n",
    "        attn    = self.sigmoid(attn)\n",
    "        return x * attn\n",
    "\n",
    "\n",
    "class UNet_SA_BN_DSC(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet_SA_BN_DSC, self).__init__()\n",
    "\n",
    "        # ---- Encoder blocks (with BN + ReLU) ----\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64,   128)\n",
    "        self.enc3 = self.conv_block(128,  256)\n",
    "        self.enc4 = self.conv_block(256,  512)\n",
    "\n",
    "        # ---- Bridge block ----\n",
    "        self.bridge = self.conv_block(512, 1024)\n",
    "\n",
    "        # ---- Spatial Attention modules for each stage ----\n",
    "        self.sa1      = SpatialAttention()\n",
    "        self.sa2      = SpatialAttention()\n",
    "        self.sa3      = SpatialAttention()\n",
    "        self.sa4      = SpatialAttention()\n",
    "        self.sa_bridge= SpatialAttention()\n",
    "\n",
    "        # ---- Decoder blocks (with BN + ReLU) + dense skip logic ----\n",
    "        # dec4: up from 1024 -> 512, merges enc4 + upsampled (enc3, enc2, enc1)\n",
    "        # total cat => 512 + 512 + 256 + 128 + 64 = 1472\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4= self.conv_block(512+512+256+128+64, 512)\n",
    "\n",
    "        # dec3: up from 512 -> 256, merges enc3 + upsampled (enc2, enc1)\n",
    "        # total cat => 256 + 256 + 128 + 64 = 704\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3= self.conv_block(256+256+128+64, 256)\n",
    "\n",
    "        # dec2: up from 256 -> 128, merges enc2 + upsampled (enc1)\n",
    "        # total cat => 128 + 128 + 64 = 320\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2= self.conv_block(128+128+64, 128)\n",
    "\n",
    "        # dec1: up from 128 -> 64, merges enc1\n",
    "        # total cat => 64 + 64 = 128\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1= self.conv_block(64+64, 64)\n",
    "\n",
    "        # ---- Final output 1Ã—1 conv ----\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    # --------------------------\n",
    "    #  2Ã— (Conv -> BN -> ReLU)\n",
    "    # --------------------------\n",
    "    def conv_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,H,W = x.shape\n",
    "\n",
    "        # =============== Encoder ===============\n",
    "        # enc1 => (B,64,H,W)\n",
    "        enc1 = self.enc1(x)\n",
    "        enc1 = self.sa1(enc1)\n",
    "\n",
    "        e2_in= F.max_pool2d(enc1, 2)               # (H/2,W/2)\n",
    "        enc2 = self.enc2(e2_in)                   # (B,128,H/2,W/2)\n",
    "        enc2 = self.sa2(enc2)\n",
    "\n",
    "        e3_in= F.max_pool2d(enc2, 2)              # (H/4,W/4)\n",
    "        enc3 = self.enc3(e3_in)                   # (B,256,H/4,W/4)\n",
    "        enc3 = self.sa3(enc3)\n",
    "\n",
    "        e4_in= F.max_pool2d(enc3, 2)              # (H/8,W/8)\n",
    "        enc4 = self.enc4(e4_in)                   # (B,512,H/8,W/8)\n",
    "        enc4 = self.sa4(enc4)\n",
    "\n",
    "        # =============== Bridge ===============\n",
    "        b_in= F.max_pool2d(enc4, 2)               # (H/16,W/16)\n",
    "        bridge = self.bridge(b_in)                # (B,1024,H/16,W/16)\n",
    "        bridge = self.sa_bridge(bridge)\n",
    "\n",
    "        # =============== Decoder ===============\n",
    "        # dec4 => up from H/16->H/8\n",
    "        dec4_up= self.up4(bridge)                 # (B,512,H/8,W/8)\n",
    "\n",
    "        # We want enc4(H/8) + upsampled enc3(H/4->H/8) + enc2(H/2->H/8) + enc1(H->H/8)\n",
    "        enc3_8= F.interpolate(enc3, scale_factor=1/2, mode='bilinear', align_corners=False)\n",
    "        enc2_8= F.interpolate(enc2, scale_factor=1/4, mode='bilinear', align_corners=False)\n",
    "        enc1_8= F.interpolate(enc1, scale_factor=1/8, mode='bilinear', align_corners=False)\n",
    "        dec4_in= torch.cat([dec4_up, enc4, enc3_8, enc2_8, enc1_8], dim=1)\n",
    "        dec4   = self.dec4(dec4_in)               # (B,512,H/8,W/8)\n",
    "\n",
    "        # dec3 => up from H/8->H/4\n",
    "        dec3_up= self.up3(dec4)                   # (B,256,H/4,W/4)\n",
    "        # cat enc3(H/4), enc2(H/2->H/4), enc1(H->H/4)\n",
    "        enc2_4= F.interpolate(enc2, scale_factor=1/2, mode='bilinear', align_corners=False)\n",
    "        enc1_4= F.interpolate(enc1, scale_factor=1/4, mode='bilinear', align_corners=False)\n",
    "        dec3_in= torch.cat([dec3_up, enc3, enc2_4, enc1_4], dim=1)\n",
    "        dec3   = self.dec3(dec3_in)               # (B,256,H/4,W/4)\n",
    "\n",
    "        # dec2 => up from H/4->H/2\n",
    "        dec2_up= self.up2(dec3)                   # (B,128,H/2,W/2)\n",
    "        # cat enc2(H/2), enc1(H->H/2)\n",
    "        enc1_2= F.interpolate(enc1, scale_factor=1/2, mode='bilinear', align_corners=False)\n",
    "        dec2_in= torch.cat([dec2_up, enc2, enc1_2], dim=1)\n",
    "        dec2   = self.dec2(dec2_in)               # (B,128,H/2,W/2)\n",
    "\n",
    "        # dec1 => up from H/2->H\n",
    "        dec1_up= self.up1(dec2)                   # (B,64,H,W)\n",
    "        # cat enc1(H)\n",
    "        dec1_in= torch.cat([dec1_up, enc1], dim=1)# (B,128,H,W)\n",
    "        dec1   = self.dec1(dec1_in)               # (B,64,H,W)\n",
    "\n",
    "        out= self.out(dec1)                       # (B,out_channels,H,W)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "IMG_HEIGHT = 640\n",
    "IMG_WIDTH = 640\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 3\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 10  # Early stopping\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "IMAGE_DIR = 'CWD-3HSV/train/images'\n",
    "MASK_DIR  = 'CWD-3HSV/train/Morphed_Images'\n",
    "VALID_IMAGE_DIR = 'CWD-3HSV/valid/images'\n",
    "VALID_MASK_DIR  = 'CWD-3HSV/valid/Morphed_Images'\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_files, mask_files, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.mask_files  = mask_files\n",
    "        self.transform   = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path  = self.image_files[idx]\n",
    "        mask_path = self.mask_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask  = Image.open(mask_path).convert('L')\n",
    "\n",
    "        # Resize\n",
    "        image = image.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        mask  = mask.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask  = torch.tensor(np.array(mask), dtype=torch.long)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith('.jpg')]\n",
    "mask_files  = [f.replace('.jpg', '_morphed.png') for f in image_files]\n",
    "\n",
    "valid_image_files = []\n",
    "valid_mask_files  = []\n",
    "for img_file in image_files:\n",
    "    mask_file = img_file.replace('.jpg', '_morphed.png')\n",
    "    if mask_file in os.listdir(MASK_DIR):\n",
    "        valid_image_files.append(os.path.join(IMAGE_DIR, img_file))\n",
    "        valid_mask_files.append(os.path.join(MASK_DIR,  mask_file))\n",
    "\n",
    "val_image_files = [os.path.join(VALID_IMAGE_DIR, f) for f in os.listdir(VALID_IMAGE_DIR) if f.endswith('.jpg')]\n",
    "val_mask_files  = [os.path.join(VALID_MASK_DIR,  f.replace('.jpg', '_morphed.png'))\n",
    "                   for f in os.listdir(VALID_IMAGE_DIR) if f.endswith('.jpg')]\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = SegmentationDataset(valid_image_files, valid_mask_files, transform=transform)\n",
    "val_dataset   = SegmentationDataset(val_image_files,   val_mask_files,   transform=transform)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader    = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "def calculate_iou(outputs, masks, num_classes):\n",
    "    # outputs: (B, num_classes, H, W)\n",
    "    outputs = torch.argmax(outputs, dim=1)\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = ((outputs == cls) & (masks == cls)).sum().item()\n",
    "        union        = ((outputs == cls) | (masks == cls)).sum().item()\n",
    "        if union == 0:\n",
    "            iou_per_class.append(float('nan'))\n",
    "        else:\n",
    "            iou_per_class.append(intersection / union)\n",
    "    return np.nanmean(iou_per_class)\n",
    "\n",
    "def calculate_iou_loss(outputs, masks, num_classes):\n",
    "    # 1 - mean IoU\n",
    "    iou = calculate_iou(outputs, masks, num_classes)\n",
    "    return 1 - iou\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss     = 0.0\n",
    "    running_iou_loss = 0.0\n",
    "    correct          = 0\n",
    "    total            = 0\n",
    "    iou_score        = 0\n",
    "\n",
    "    for images, masks in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs  = model(images)\n",
    "        loss     = criterion(outputs, masks)\n",
    "        iou_loss = calculate_iou_loss(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss     += loss.item()\n",
    "        running_iou_loss += iou_loss\n",
    "        _, predicted     = torch.max(outputs, 1)\n",
    "        total           += masks.numel()\n",
    "        correct         += (predicted == masks).sum().item()\n",
    "        iou_score       += calculate_iou(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "    epoch_loss      = running_loss / len(data_loader)\n",
    "    epoch_iou_loss  = running_iou_loss / len(data_loader)\n",
    "    epoch_accuracy  = correct / total * 100\n",
    "    epoch_iou       = iou_score / len(data_loader)\n",
    "    return epoch_loss, epoch_accuracy, epoch_iou, epoch_iou_loss\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss     = 0.0\n",
    "    running_iou_loss = 0.0\n",
    "    correct          = 0\n",
    "    total            = 0\n",
    "    iou_score        = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(data_loader, desc=\"Validation\", leave=False):\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "            outputs  = model(images)\n",
    "            loss     = criterion(outputs, masks)\n",
    "            iou_loss = calculate_iou_loss(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "            running_loss     += loss.item()\n",
    "            running_iou_loss += iou_loss\n",
    "            _, predicted     = torch.max(outputs, 1)\n",
    "            total           += masks.numel()\n",
    "            correct         += (predicted == masks).sum().item()\n",
    "            iou_score       += calculate_iou(outputs, masks, NUM_CLASSES)\n",
    "\n",
    "    epoch_loss      = running_loss / len(data_loader)\n",
    "    epoch_iou_loss  = running_iou_loss / len(data_loader)\n",
    "    epoch_accuracy  = correct / total * 100\n",
    "    epoch_iou       = iou_score / len(data_loader)\n",
    "    return epoch_loss, epoch_accuracy, epoch_iou, epoch_iou_loss\n",
    "\n",
    "def train_and_evaluate_model(model_name, model_class, \n",
    "                             train_loader, val_loader,\n",
    "                             epochs=EPOCHS, patience=PATIENCE):\n",
    "    \"\"\"\n",
    "    Train a given model with the specified name/class \n",
    "    and store best model + metrics in a separate folder.\n",
    "    \"\"\"\n",
    "    # 1) Create directory for this model\n",
    "    model_dir = model_name\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Instantiate model + move to device\n",
    "    model = model_class(in_channels=3, out_channels=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "    # 3) Define optimizer + loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss   = float('inf')\n",
    "    best_model_path = None\n",
    "    patience_counter= 0\n",
    "    records         = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n[{model_name}] Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        train_loss, train_accuracy, train_iou, train_iou_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Train IoU: {train_iou:.4f}, Train IoU Loss: {train_iou_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_accuracy, val_iou, val_iou_loss = evaluate(model, val_loader, criterion)\n",
    "        print(f\"Val Loss:   {val_loss:.4f}, Val Accuracy:   {val_accuracy:.2f}%, \"\n",
    "              f\"Val IoU:   {val_iou:.4f}, Val IoU Loss:   {val_iou_loss:.4f}\")\n",
    "\n",
    "        records.append([\n",
    "            epoch+1, \n",
    "            train_loss, \n",
    "            train_accuracy, \n",
    "            val_loss, \n",
    "            val_accuracy, \n",
    "            train_iou_loss, \n",
    "            train_iou, \n",
    "            val_iou_loss, \n",
    "            val_iou\n",
    "        ])\n",
    "\n",
    "        # early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "            torch.save(model, best_model_path)\n",
    "            print(f\"  [*] Best model saved at {best_model_path}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  [!] Early stopping for {model_name}\")\n",
    "            break\n",
    "\n",
    "    # 4) Save Training_Metrics.xlsx in model_dir\n",
    "    excel_path = os.path.join(model_dir, \"Training_Metrics.xlsx\")\n",
    "    columns = [\n",
    "        \"Epoch\", \n",
    "        \"Training Loss\", \n",
    "        \"Training Accuracy\", \n",
    "        \"Validation Loss\", \n",
    "        \"Validation Accuracy\", \n",
    "        \"Training IoU loss\", \n",
    "        \"Mean Training IoU\", \n",
    "        \"Validation IoU loss\", \n",
    "        \"Mean Validation IoU\"\n",
    "    ]\n",
    "    df = pd.DataFrame(records, columns=columns)\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    print(f\"  Metrics saved to {excel_path}\")\n",
    "\n",
    "    print(f\"Done training {model_name}.\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of models you want to train\n",
    "    models_to_train = {\n",
    "        #\"Unet\"         : UNet,\n",
    "        #\"Unet-BN\"      : UNet_BN,\n",
    "        #\"Unet-SA\"      : UNet_SA,\n",
    "        #\"Unet-DSC\"     : UNet_DSC,\n",
    "        \"Unet-SA-5L\" : UNet_SA_5L,\n",
    "        \"Unet-SA-DR-LR\" : UNet_SA_DR_LR,\n",
    "        #\"Unet-SA-BN\"    : UNet_SA_BN,\n",
    "        #\"Unet-BN-SA-DSC\": UNet_SA_BN_DSC\n",
    "    }\n",
    "\n",
    "    for model_name, model_class in models_to_train.items():\n",
    "        train_and_evaluate_model(model_name, model_class, \n",
    "                                 train_loader, val_loader,\n",
    "                                 epochs=EPOCHS, patience=PATIENCE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Prediction Images Of Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Turn off interactive backend (no pop-up windows)\n",
    "\n",
    "TEST_IMAGE_FOLDER       = 'CWD-3HSV/test/images'\n",
    "GROUND_TRUTH_MASK_FOLDER= 'CWD-3HSV/test/Morphed_Images'\n",
    "IMG_HEIGHT              = 640\n",
    "IMG_WIDTH               = 640\n",
    "NUM_CLASSES             = 3\n",
    "DEVICE                  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "def load_full_model(model_path):\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_ground_truth_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "\n",
    "def generate_segmentation_mask(model, image):\n",
    "    with torch.no_grad():\n",
    "        output = model(image)        # (B, NUM_CLASSES, H, W)\n",
    "        pred   = torch.argmax(output, dim=1)\n",
    "        return pred.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "def visualize_and_save_comparison(\n",
    "    model, input_image, gt_mask, class_rgb_mapping, input_image_path,\n",
    "    save_folder, save_predictions=True\n",
    "):\n",
    "    # Load the original image for visualization\n",
    "    original_image = Image.open(input_image_path).convert('RGB')\n",
    "    original_image = original_image.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    # Generate predicted mask\n",
    "    pred_mask = generate_segmentation_mask(model, input_image)\n",
    "\n",
    "    # Map predicted mask to RGB\n",
    "    rgb_pred_mask = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)\n",
    "    for class_id, rgb_value in class_rgb_mapping.items():\n",
    "        rgb_pred_mask[pred_mask == class_id] = rgb_value\n",
    "\n",
    "    # Map ground truth to RGB\n",
    "    rgb_gt_mask = np.zeros((gt_mask.shape[0], gt_mask.shape[1], 3), dtype=np.uint8)\n",
    "    for class_id, rgb_value in class_rgb_mapping.items():\n",
    "        rgb_gt_mask[gt_mask == class_id] = rgb_value\n",
    "\n",
    "    # Plot side-by-side\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(rgb_gt_mask)\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(rgb_pred_mask)\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the figure (no plt.show())\n",
    "    if save_predictions:\n",
    "        # For the figure\n",
    "        fig_filename = os.path.splitext(os.path.basename(input_image_path))[0] + '_compare.png'\n",
    "        fig_save_path= os.path.join(save_folder, fig_filename)\n",
    "        fig.savefig(fig_save_path, bbox_inches='tight')\n",
    "\n",
    "        # For the predicted mask alone\n",
    "        pred_mask_img = Image.fromarray(rgb_pred_mask)\n",
    "        pred_filename = os.path.splitext(os.path.basename(input_image_path))[0] + '_predmask.png'\n",
    "        pred_save_path= os.path.join(save_folder, pred_filename)\n",
    "        pred_mask_img.save(pred_save_path)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Class-to-RGB mapping\n",
    "# -------------------------------------------------------------------\n",
    "class_rgb_mapping = {\n",
    "    0: (0, 0, 0),    # black\n",
    "    1: (0, 255, 0),  # green\n",
    "    2: (255, 0, 0),  # red\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# MAIN: \n",
    "# 1) Find all \"Unet-...\" directories\n",
    "# 2) For each, load \"unet_best_model.pth\"\n",
    "# 3) Randomly pick 5 test images, generate predictions\n",
    "# 4) Save side-by-side figure + predicted mask\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Silence any console printing\n",
    "    # (Here we can reassign print to a no-op if needed)\n",
    "    def no_op(*args, **kwargs):\n",
    "        pass\n",
    "    print = no_op\n",
    "\n",
    "    # 1) Find directories that start with \"Unet-\"\n",
    "    all_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "    # 2) For each directory, load unet_best_model.pth\n",
    "    # and do random predictions\n",
    "    test_image_files = [\n",
    "        f for f in os.listdir(TEST_IMAGE_FOLDER)\n",
    "        if f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png')\n",
    "    ]\n",
    "    # If <5 images exist, use them all\n",
    "    if len(test_image_files) <= 5:\n",
    "        selected_images = test_image_files\n",
    "    else:\n",
    "        selected_images = random.sample(test_image_files, 5)\n",
    "\n",
    "    for model_dir in all_dirs:\n",
    "        model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "        if not os.path.isfile(model_path):\n",
    "            continue  # skip if no best model in that dir\n",
    "\n",
    "        # Create a subfolder \"Predictions\" inside model_dir\n",
    "        pred_save_folder = os.path.join(model_dir, \"Predictions\")\n",
    "        os.makedirs(pred_save_folder, exist_ok=True)\n",
    "\n",
    "        # Load model\n",
    "        model = load_full_model(model_path)\n",
    "\n",
    "        # For each selected image, compare\n",
    "        for image_file in selected_images:\n",
    "            input_image_path = os.path.join(TEST_IMAGE_FOLDER, image_file)\n",
    "            # ground truth\n",
    "            gt_mask_name = os.path.splitext(image_file)[0] + '_morphed.png'\n",
    "            gt_mask_path = os.path.join(GROUND_TRUTH_MASK_FOLDER, gt_mask_name)\n",
    "\n",
    "            input_image = preprocess_image(input_image_path)\n",
    "            ground_truth_mask = load_ground_truth_mask(gt_mask_path)\n",
    "\n",
    "            # Visualize and save\n",
    "            visualize_and_save_comparison(\n",
    "                model=model,\n",
    "                input_image=input_image,\n",
    "                gt_mask=ground_truth_mask,\n",
    "                class_rgb_mapping=class_rgb_mapping,\n",
    "                input_image_path=input_image_path,\n",
    "                save_folder=pred_save_folder,\n",
    "                save_predictions=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Turn off interactive display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "TEST_IMAGES_DIR = 'CWD-3HSV/test/images'\n",
    "TEST_MASKS_DIR  = 'CWD-3HSV/test/Morphed_Images'\n",
    "IMG_HEIGHT      = 640\n",
    "IMG_WIDTH       = 640\n",
    "NUM_CLASSES     = 3\n",
    "DEVICE          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Suppress console output\n",
    "def no_op(*args, **kwargs):\n",
    "    pass\n",
    "print = no_op  # Overwrite default print\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "def preprocess_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "\n",
    "def generate_predictions(model, image):\n",
    "    with torch.no_grad():\n",
    "        output = model(image)            # [B, NUM_CLASSES, H, W]\n",
    "        pred   = torch.argmax(output, 1) # pick class with max logit\n",
    "        return pred.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "def calculate_iou(pred_mask, gt_mask, num_classes):\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = np.logical_and(pred_mask == cls, gt_mask == cls).sum()\n",
    "        union        = np.logical_or(pred_mask == cls, gt_mask == cls).sum()\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        iou_per_class.append(iou)\n",
    "    return iou_per_class\n",
    "\n",
    "def calculate_dice(pred_mask, gt_mask, num_classes):\n",
    "    dice_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = np.logical_and(pred_mask == cls, gt_mask == cls).sum()\n",
    "        denom        = (np.sum(pred_mask == cls) + np.sum(gt_mask == cls))\n",
    "        dice         = 2.0 * intersection / denom if denom > 0 else 0\n",
    "        dice_per_class.append(dice)\n",
    "    return dice_per_class\n",
    "\n",
    "def calculate_jaccard(pred_mask, gt_mask, num_classes):\n",
    "    jaccard_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = np.logical_and(pred_mask == cls, gt_mask == cls).sum()\n",
    "        union        = np.logical_or(pred_mask == cls, gt_mask == cls).sum()\n",
    "        jaccard      = intersection / union if union > 0 else 0\n",
    "        jaccard_per_class.append(jaccard)\n",
    "    return jaccard_per_class\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, save_path, title=\"Confusion Matrix\", fmt='d'):\n",
    "    \"\"\"\n",
    "    'fmt': 'd' for counts, '.2f' for percentages\n",
    "    Saves the figure to 'save_path'.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_images_dir, test_masks_dir, num_classes, results_dir):\n",
    "    all_pred = []\n",
    "    all_gt   = []\n",
    "\n",
    "    iou_per_class       = np.zeros(num_classes)\n",
    "    dice_per_class      = np.zeros(num_classes)\n",
    "    jaccard_per_class   = np.zeros(num_classes)\n",
    "    accuracy_per_class  = np.zeros(num_classes)\n",
    "    precision_per_class = np.zeros(num_classes)\n",
    "    recall_per_class    = np.zeros(num_classes)\n",
    "    f1_per_class        = np.zeros(num_classes)\n",
    "\n",
    "    image_files  = [img for img in os.listdir(test_images_dir) if img.endswith('.jpg')]\n",
    "    total_samples= 0\n",
    "\n",
    "    for img_name in image_files:\n",
    "        image_path = os.path.join(test_images_dir, img_name)\n",
    "        mask_name  = img_name.replace('.jpg', '_morphed.png')\n",
    "        mask_path  = os.path.join(test_masks_dir, mask_name)\n",
    "\n",
    "        image   = preprocess_image(image_path)\n",
    "        gt_mask = preprocess_mask(mask_path)\n",
    "        pred_mask= generate_predictions(model, image)\n",
    "\n",
    "        # Flatten\n",
    "        all_pred.extend(pred_mask.flatten())\n",
    "        all_gt.extend(gt_mask.flatten())\n",
    "\n",
    "        # iou/dice/jaccard\n",
    "        iou_sample     = calculate_iou(pred_mask,     gt_mask, num_classes)\n",
    "        dice_sample    = calculate_dice(pred_mask,    gt_mask, num_classes)\n",
    "        jaccard_sample = calculate_jaccard(pred_mask, gt_mask, num_classes)\n",
    "\n",
    "        iou_per_class     += np.array(iou_sample)\n",
    "        dice_per_class    += np.array(dice_sample)\n",
    "        jaccard_per_class += np.array(jaccard_sample)\n",
    "\n",
    "        # per-class metrics\n",
    "        for cls in range(num_classes):\n",
    "            tp = np.sum((pred_mask == cls) & (gt_mask == cls))\n",
    "            fp = np.sum((pred_mask == cls) & (gt_mask != cls))\n",
    "            fn = np.sum((pred_mask != cls) & (gt_mask == cls))\n",
    "            total_class_pixels= np.sum(gt_mask == cls)\n",
    "            accuracy_per_class[cls] += tp / (total_class_pixels + 1e-6)\n",
    "\n",
    "            precision_per_class[cls]+= tp / (tp + fp + 1e-6)\n",
    "            recall_per_class[cls]   += tp / (tp + fn + 1e-6)\n",
    "            f1_per_class[cls]       += 2*tp / (2*tp + fp + fn + 1e-6)\n",
    "\n",
    "        total_samples += 1\n",
    "\n",
    "    # Normalize\n",
    "    accuracy_per_class  /= total_samples\n",
    "    precision_per_class /= total_samples\n",
    "    recall_per_class    /= total_samples\n",
    "    f1_per_class        /= total_samples\n",
    "    iou_per_class       /= total_samples\n",
    "    dice_per_class      /= total_samples\n",
    "    jaccard_per_class   /= total_samples\n",
    "\n",
    "    mean_dice     = np.mean(dice_per_class)\n",
    "    mean_jaccard  = np.mean(jaccard_per_class)\n",
    "\n",
    "    # freq weighted iou\n",
    "    all_gt_arr = np.array(all_gt)\n",
    "    class_counts= np.bincount(all_gt_arr, minlength=num_classes)\n",
    "    frequency_weighted_iou= np.average(iou_per_class, weights=class_counts)\n",
    "\n",
    "    # overall metrics\n",
    "    all_pred_arr = np.array(all_pred)\n",
    "    accuracy = (all_pred_arr == all_gt_arr).sum()/len(all_gt_arr)\n",
    "    precision= precision_score(all_gt_arr, all_pred_arr, average='weighted', zero_division=1)\n",
    "    recall   = recall_score(all_gt_arr,    all_pred_arr, average='weighted', zero_division=1)\n",
    "    f1       = f1_score(all_gt_arr,        all_pred_arr, average='weighted', zero_division=1)\n",
    "\n",
    "    mean_iou    = np.mean(iou_per_class)\n",
    "    weighted_iou= np.average(iou_per_class, weights=np.bincount(all_gt_arr))\n",
    "\n",
    "    # confusion matrix\n",
    "    confusion_matrix_counts= np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    for gt_val, pr_val in zip(all_gt_arr, all_pred_arr):\n",
    "        confusion_matrix_counts[gt_val, pr_val]+=1\n",
    "\n",
    "    confusion_matrix_percent= np.zeros_like(confusion_matrix_counts, dtype=float)\n",
    "    for r in range(num_classes):\n",
    "        row_sum = confusion_matrix_counts[r,:].sum()\n",
    "        if row_sum > 0:\n",
    "            confusion_matrix_percent[r,:] = (confusion_matrix_counts[r,:]/ row_sum)*100\n",
    "\n",
    "    class_names= [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "    # Save confusion matrices as PNG\n",
    "    cm_counts_path  = os.path.join(results_dir, \"Confusion_Matrix_Counts.png\")\n",
    "    cm_percent_path = os.path.join(results_dir, \"Confusion_Matrix_Percent.png\")\n",
    "    plot_confusion_matrix(confusion_matrix_counts,  class_names, save_path=cm_counts_path,  title=\"Confusion Matrix (Counts)\", fmt='d')\n",
    "    plot_confusion_matrix(confusion_matrix_percent, class_names, save_path=cm_percent_path, title=\"Confusion Matrix (Percent)\", fmt='.2f')\n",
    "\n",
    "    return (\n",
    "        accuracy, accuracy_per_class, precision, precision_per_class,\n",
    "        recall, recall_per_class, f1, f1_per_class,\n",
    "        iou_per_class, mean_iou, weighted_iou, frequency_weighted_iou,\n",
    "        dice_per_class, jaccard_per_class, mean_dice, mean_jaccard\n",
    "    )\n",
    "\n",
    "def save_results_to_excel(\n",
    "    model_name,\n",
    "    accuracy, accuracy_per_class,\n",
    "    precision, precision_per_class,\n",
    "    recall, recall_per_class,\n",
    "    f1, f1_per_class,\n",
    "    iou_per_class, mean_iou,\n",
    "    weighted_iou, frequency_weighted_iou,\n",
    "    dice_per_class, jaccard_per_class,\n",
    "    mean_dice, mean_jaccard,\n",
    "    save_directory\n",
    "):\n",
    "    # We'll store the final xlsx in the same directory as the model\n",
    "    excel_path = os.path.join(save_directory, \"Performance_Evaluation_Metrics.xlsx\")\n",
    "\n",
    "    columns = (\n",
    "        ['Model Name', 'Accuracy']\n",
    "        + [f'Accuracy Class {i}' for i in range(len(accuracy_per_class))]\n",
    "        + ['Precision'] + [f'Precision Class {i}' for i in range(len(precision_per_class))]\n",
    "        + ['Recall'] + [f'Recall Class {i}' for i in range(len(recall_per_class))]\n",
    "        + ['F1 Score'] + [f'F1 Score Class {i}' for i in range(len(f1_per_class))]\n",
    "        + [f'IoU Class {i}' for i in range(len(iou_per_class))]\n",
    "        + ['Mean IoU', 'Weighted IoU', 'Frequency Weighted IoU']\n",
    "        + [f'Dice Coefficient Class {i}' for i in range(len(dice_per_class))]\n",
    "        + ['Mean Dice']\n",
    "        + [f'Jaccard Index Class {i}' for i in range(len(jaccard_per_class))]\n",
    "        + ['Mean Jaccard']\n",
    "    )\n",
    "\n",
    "    new_row = {\n",
    "        'Model Name': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        **{f'Accuracy Class {i}': acc for i, acc in enumerate(accuracy_per_class)},\n",
    "        'Precision': precision,\n",
    "        **{f'Precision Class {i}': prec for i, prec in enumerate(precision_per_class)},\n",
    "        'Recall': recall,\n",
    "        **{f'Recall Class {i}': r for i, r in enumerate(recall_per_class)},\n",
    "        'F1 Score': f1,\n",
    "        **{f'F1 Score Class {i}': f1c for i, f1c in enumerate(f1_per_class)},\n",
    "        **{f'IoU Class {i}': iou for i, iou in enumerate(iou_per_class)},\n",
    "        'Mean IoU': mean_iou,\n",
    "        'Weighted IoU': weighted_iou,\n",
    "        'Frequency Weighted IoU': frequency_weighted_iou,\n",
    "        **{f'Dice Coefficient Class {i}': d for i, d in enumerate(dice_per_class)},\n",
    "        'Mean Dice': mean_dice,\n",
    "        **{f'Jaccard Index Class {i}': j for i, j in enumerate(jaccard_per_class)},\n",
    "        'Mean Jaccard': mean_jaccard,\n",
    "    }\n",
    "\n",
    "    new_data = pd.DataFrame([new_row], columns=columns)\n",
    "\n",
    "    # Overwrite any existing file to store only the last row\n",
    "    new_data.to_excel(excel_path, index=False, header=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppress console output\n",
    "    def no_op(*args, **kwargs):\n",
    "        pass\n",
    "    print = no_op  # Overwrite default print\n",
    "\n",
    "    # 1) Find all directories that match \"Unet-<backbone>\"\n",
    "    all_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "    for model_dir in all_dirs:\n",
    "        # 2) Load \"unet_best_model.pth\" in that directory, if exists\n",
    "        model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "        if not os.path.isfile(model_path):\n",
    "            continue  # skip if no best model found\n",
    "\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # 3) Evaluate\n",
    "        results = evaluate_model(\n",
    "            model=model,\n",
    "            test_images_dir=TEST_IMAGES_DIR,\n",
    "            test_masks_dir=TEST_MASKS_DIR,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            results_dir=model_dir  # store confusion matrix PNG in same directory\n",
    "        )\n",
    "\n",
    "        # 4) Unpack\n",
    "        (\n",
    "            accuracy, accuracy_per_class,\n",
    "            precision, precision_per_class,\n",
    "            recall, recall_per_class,\n",
    "            f1, f1_per_class,\n",
    "            iou_per_class, mean_iou,\n",
    "            weighted_iou, frequency_weighted_iou,\n",
    "            dice_per_class, jaccard_per_class,\n",
    "            mean_dice, mean_jaccard\n",
    "        ) = results\n",
    "\n",
    "        # 5) Save row to \"Performance_Evaluation_Metrics.xlsx\" in model_dir\n",
    "        save_results_to_excel(\n",
    "            model_name=model_dir,\n",
    "            accuracy=accuracy,\n",
    "            accuracy_per_class=accuracy_per_class,\n",
    "            precision=precision,\n",
    "            precision_per_class=precision_per_class,\n",
    "            recall=recall,\n",
    "            recall_per_class=recall_per_class,\n",
    "            f1=f1,\n",
    "            f1_per_class=f1_per_class,\n",
    "            iou_per_class=iou_per_class,\n",
    "            mean_iou=mean_iou,\n",
    "            weighted_iou=weighted_iou,\n",
    "            frequency_weighted_iou=frequency_weighted_iou,\n",
    "            dice_per_class=dice_per_class,\n",
    "            jaccard_per_class=jaccard_per_class,\n",
    "            mean_dice=mean_dice,\n",
    "            mean_jaccard=mean_jaccard,\n",
    "            save_directory=model_dir\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Training Curves Of Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # So figures don't pop up; they are just saved\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves_for_model(excel_path, output_dir):\n",
    "    \"\"\"\n",
    "    Reads Training_Metrics.xlsx from excel_path and saves four plots in output_dir.\n",
    "    \"\"\"\n",
    "    # Read Excel\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    # Extract columns\n",
    "    epochs            = df['Epoch']\n",
    "    train_loss        = df['Training Loss']\n",
    "    val_loss          = df['Validation Loss']\n",
    "    train_acc         = df['Training Accuracy']\n",
    "    val_acc           = df['Validation Accuracy']\n",
    "    train_iou_loss    = df['Training IoU loss']\n",
    "    val_iou_loss      = df['Validation IoU loss']\n",
    "    mean_train_iou    = df['Mean Training IoU']\n",
    "    mean_val_iou      = df['Mean Validation IoU']\n",
    "\n",
    "    # 1) Training vs Validation Loss\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, train_loss, label='Training Loss', marker='o')\n",
    "    plt.plot(epochs, val_loss,   label='Validation Loss', marker='s')\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    loss_plot_path = os.path.join(output_dir, 'Train_vs_Val_Loss.png')\n",
    "    plt.savefig(loss_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 2) Training vs Validation Accuracy\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, train_acc, label='Training Accuracy', marker='o')\n",
    "    plt.plot(epochs, val_acc,   label='Validation Accuracy', marker='s')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    acc_plot_path = os.path.join(output_dir, 'Train_vs_Val_Accuracy.png')\n",
    "    plt.savefig(acc_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 3) Training IoU Loss vs Validation IoU Loss\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, train_iou_loss, label='Training IoU Loss', marker='o')\n",
    "    plt.plot(epochs, val_iou_loss,   label='Validation IoU Loss', marker='s')\n",
    "    plt.title('Training vs Validation IoU Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    iou_loss_plot_path = os.path.join(output_dir, 'Train_vs_Val_IoU_Loss.png')\n",
    "    plt.savefig(iou_loss_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 4) Mean Training IoU vs Mean Validation IoU\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, mean_train_iou, label='Mean Training IoU', marker='o')\n",
    "    plt.plot(epochs, mean_val_iou,   label='Mean Validation IoU', marker='s')\n",
    "    plt.title('Mean Training IoU vs Mean Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    iou_plot_path = os.path.join(output_dir, 'Mean_Train_vs_Val_IoU.png')\n",
    "    plt.savefig(iou_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # 1) Find directories named \"Unet-...\"\n",
    "    unet_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith('Unet')]\n",
    "\n",
    "    for unet_dir in unet_dirs:\n",
    "        # 2) The path to the Training_Metrics.xlsx\n",
    "        excel_path = os.path.join(unet_dir, 'Training_Metrics.xlsx')\n",
    "        if not os.path.isfile(excel_path):\n",
    "            continue  # skip if no metrics file\n",
    "\n",
    "        # 3) Create \"Training_Curves\" subdir\n",
    "        curves_dir = os.path.join(unet_dir, 'Training_Curves')\n",
    "        os.makedirs(curves_dir, exist_ok=True)\n",
    "\n",
    "        # 4) Generate + save plots\n",
    "        plot_training_curves_for_model(excel_path, curves_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models Performance Evaluation Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Automatically discover directories named \"Unet-...\"\n",
    "model_directories = [\n",
    "    d for d in os.listdir('.') \n",
    "    if os.path.isdir(d) and d.startswith(\"Unet\")\n",
    "]\n",
    "\n",
    "# 2) Each directory's Excel file name\n",
    "excel_filename = \"Performance_Evaluation_Metrics.xlsx\"\n",
    "\n",
    "# 3) Where to save the merged file\n",
    "results_folder = \"Results\"\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "merged_excel_path = os.path.join(results_folder, \"All_Models_Performance_Evaluation_Metrics.xlsx\")\n",
    "\n",
    "# 4) Create an empty list to hold the last rows from each subdirectory\n",
    "merged_rows = []\n",
    "\n",
    "# 5) Loop over each Unet-<backbone> directory\n",
    "for model_dir in model_directories:\n",
    "    excel_path = os.path.join(model_dir, excel_filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(excel_path):\n",
    "        print(f\"Warning: {excel_path} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Read entire Excel file\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"Warning: {excel_path} is empty. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Get the last (bottom) row\n",
    "    last_row = df.iloc[[-1]].copy()\n",
    "    merged_rows.append(last_row)\n",
    "\n",
    "# 6) If we have rows, concatenate them; otherwise create empty DataFrame\n",
    "if len(merged_rows) > 0:\n",
    "    merged_df = pd.concat(merged_rows, ignore_index=True)\n",
    "else:\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "# 7) Overwrite the final Excel file with these rows\n",
    "merged_df.to_excel(merged_excel_path, index=False)\n",
    "print(f\"Merged file saved to: {merged_excel_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Predictions For All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Automatically gather all directories starting with \"Unet-\"\n",
    "# ------------------------------------------------------------------------------\n",
    "all_dirs = [d for d in os.listdir('.') if os.path.isdir(d)]\n",
    "model_dirs = [d for d in all_dirs if d.startswith(\"Unet-\")]\n",
    "models_info = [(d, os.path.join(d, \"unet_best_model.pth\")) for d in model_dirs]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Define directories / file paths and hyperparameters\n",
    "# ------------------------------------------------------------------------------\n",
    "TEST_IMAGE_FOLDER        = 'CWD-3HSV/test/images/'\n",
    "GROUND_TRUTH_MASK_FOLDER = 'CWD-3HSV/test/Morphed_Images/'\n",
    "PREDICTION_SAVE_FOLDER   = 'Predictions'\n",
    "os.makedirs(PREDICTION_SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "IMG_HEIGHT  = 640\n",
    "IMG_WIDTH   = 640\n",
    "NUM_CLASSES = 3\n",
    "DEVICE      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Define transformation (as used during training)\n",
    "# ------------------------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Helper functions\n",
    "# ------------------------------------------------------------------------------\n",
    "def load_full_model(model_path):\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    return image\n",
    "\n",
    "def load_ground_truth_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "def generate_segmentation_mask(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)  # shape: (B, NUM_CLASSES, H, W)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        return pred.squeeze().cpu().numpy()  # shape: (H, W)\n",
    "\n",
    "def mask_to_rgb(mask_array):\n",
    "    h, w = mask_array.shape\n",
    "    rgb_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    # Define the mapping for 3 classes\n",
    "    class_rgb_mapping = {\n",
    "        0: (0, 0, 0),      # Black for background (or class 0)\n",
    "        1: (0, 255, 0),    # Green for class 1\n",
    "        2: (255, 0, 0)     # Red for class 2\n",
    "    }\n",
    "    for cls, color in class_rgb_mapping.items():\n",
    "        rgb_image[mask_array == cls] = color\n",
    "    return rgb_image\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) Main execution: load models, select images, and create merged figure\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load all models\n",
    "    loaded_models = []\n",
    "    for model_name, model_path in models_info:\n",
    "        if not os.path.isfile(model_path):\n",
    "            continue\n",
    "        model = load_full_model(model_path)\n",
    "        loaded_models.append((model_name, model))\n",
    "    if len(loaded_models) == 0:\n",
    "        exit(0)\n",
    "    \n",
    "    # Gather test images\n",
    "    test_image_files = [f for f in os.listdir(TEST_IMAGE_FOLDER) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "    if len(test_image_files) == 0:\n",
    "        exit(0)\n",
    "    \n",
    "    # Randomly select up to 5 images\n",
    "    selected_images = random.sample(test_image_files, 5) if len(test_image_files) >= 5 else test_image_files\n",
    "\n",
    "    # Set up figure:\n",
    "    n_rows = len(selected_images)\n",
    "    n_cols = 2 + len(loaded_models)  # 1: Input, 1: GT, rest: each model's prediction\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 4.2 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes]  # ensure axes is a list of rows\n",
    "\n",
    "    # Process each image:\n",
    "    for row_idx, image_file in enumerate(selected_images):\n",
    "        input_image_path = os.path.join(TEST_IMAGE_FOLDER, image_file)\n",
    "        gt_mask_name = os.path.splitext(image_file)[0] + '_morphed.png'\n",
    "        gt_mask_path = os.path.join(GROUND_TRUTH_MASK_FOLDER, gt_mask_name)\n",
    "\n",
    "        # Load and resize input image and ground truth mask for display\n",
    "        original_image = Image.open(input_image_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        gt_mask_np = load_ground_truth_mask(gt_mask_path)\n",
    "        gt_rgb = mask_to_rgb(gt_mask_np)\n",
    "\n",
    "        # Preprocess image for model inference\n",
    "        input_tensor = preprocess_image(input_image_path)\n",
    "\n",
    "        # Column 0: Input image\n",
    "        axes[row_idx][0].imshow(original_image)\n",
    "        if row_idx == 0:\n",
    "            axes[row_idx][0].set_title(\"Input Image\", fontsize=27)\n",
    "        axes[row_idx][0].axis('off')\n",
    "\n",
    "        # Column 1: Ground truth mask\n",
    "        axes[row_idx][1].imshow(gt_rgb)\n",
    "        if row_idx == 0:\n",
    "            axes[row_idx][1].set_title(\"Ground Truth Mask\", fontsize=27)\n",
    "        axes[row_idx][1].axis('off')\n",
    "\n",
    "        # Next columns: Predictions from each model\n",
    "        for model_i, (model_name, model_obj) in enumerate(loaded_models):\n",
    "            pred_mask = generate_segmentation_mask(model_obj, input_tensor)\n",
    "            pred_rgb = mask_to_rgb(pred_mask)\n",
    "            col_idx = 2 + model_i\n",
    "            axes[row_idx][col_idx].imshow(pred_rgb)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][col_idx].set_title(f\"{model_name} \\nPredicted Mask\", fontsize=27)\n",
    "            axes[row_idx][col_idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    merged_filename = os.path.join(PREDICTION_SAVE_FOLDER, \"All_Models_Predictions.png\")\n",
    "    plt.savefig(merged_filename, bbox_inches='tight',dpi=200)\n",
    "    # Uncomment the next line if you wish to display the figure interactively\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Predictions of Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Automatically gather all directories starting with \"Unet-\"\n",
    "# ------------------------------------------------------------------------------\n",
    "model_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Define directories and hyperparameters\n",
    "# ------------------------------------------------------------------------------\n",
    "TEST_IMAGE_FOLDER        = 'CWD-3HSV/test/images/'\n",
    "GROUND_TRUTH_MASK_FOLDER = 'CWD-3HSV/test/Morphed_Images/'\n",
    "# (The merged prediction figure for each model will be saved in a \"Predictions\" subfolder of that model directory.)\n",
    "IMG_HEIGHT  = 640\n",
    "IMG_WIDTH   = 640\n",
    "NUM_CLASSES = 3\n",
    "DEVICE      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Define the transformation (as used during training)\n",
    "# ------------------------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Helper functions\n",
    "# ------------------------------------------------------------------------------\n",
    "def load_full_model(model_dir):\n",
    "    \"\"\"Load the full model from <model_dir>/unet_best_model.pth.\"\"\"\n",
    "    model_path = os.path.join(model_dir, \"unet_best_model.pth\")\n",
    "    if not os.path.isfile(model_path):\n",
    "        return None\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    return image\n",
    "\n",
    "def load_ground_truth_mask(mask_path):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "    return np.array(mask)\n",
    "\n",
    "def generate_segmentation_mask(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        # model outputs logits of shape (B, NUM_CLASSES, H, W)\n",
    "        output = model(image_tensor)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        return pred.squeeze().cpu().numpy()  # shape: (H, W)\n",
    "\n",
    "def mask_to_rgb(mask_array):\n",
    "    h, w = mask_array.shape\n",
    "    rgb_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    # Fixed mapping for 3 classes\n",
    "    class_rgb_mapping = {\n",
    "        0: (0, 0, 0),      # Black\n",
    "        1: (0, 255, 0),    # Green\n",
    "        2: (255, 0, 0)     # Red\n",
    "    }\n",
    "    for cls, color in class_rgb_mapping.items():\n",
    "        rgb_image[mask_array == cls] = color\n",
    "    return rgb_image\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) Main execution: Process each model directory\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Gather test images (all jpg/jpeg/png)\n",
    "    test_image_files = [f for f in os.listdir(TEST_IMAGE_FOLDER) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "    if len(test_image_files) == 0:\n",
    "        exit(0)\n",
    "    \n",
    "    # Randomly select up to 5 images\n",
    "    selected_images = random.sample(test_image_files, 5) if len(test_image_files) >= 5 else test_image_files\n",
    "\n",
    "    # Process each model directory that starts with \"Unet-\"\n",
    "    for model_dir in model_dirs:\n",
    "        model = load_full_model(model_dir)\n",
    "        if model is None:\n",
    "            continue\n",
    "        \n",
    "        # Create a Predictions subfolder inside the model directory\n",
    "        predictions_dir = os.path.join(model_dir, \"Predictions\")\n",
    "        os.makedirs(predictions_dir, exist_ok=True)\n",
    "        \n",
    "        # Set up a figure with one row per image and 3 columns (Input, Ground Truth, Predicted)\n",
    "        n_rows = len(selected_images)\n",
    "        n_cols = 3\n",
    "        fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(4 * n_cols, 4.2 * n_rows))\n",
    "        if n_rows == 1:\n",
    "            axes = [axes]  # Ensure axes is a list of rows\n",
    "\n",
    "        for row_idx, image_file in enumerate(selected_images):\n",
    "            input_image_path = os.path.join(TEST_IMAGE_FOLDER, image_file)\n",
    "            gt_mask_name = os.path.splitext(image_file)[0] + '_morphed.png'\n",
    "            gt_mask_path = os.path.join(GROUND_TRUTH_MASK_FOLDER, gt_mask_name)\n",
    "            \n",
    "            # Load original image and ground truth for display\n",
    "            original_image = Image.open(input_image_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "            gt_mask_np = load_ground_truth_mask(gt_mask_path)\n",
    "            gt_rgb = mask_to_rgb(gt_mask_np)\n",
    "            \n",
    "            # Preprocess image for inference\n",
    "            input_tensor = preprocess_image(input_image_path)\n",
    "            \n",
    "            # Column 0: Input image\n",
    "            axes[row_idx][0].imshow(original_image)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][0].set_title(\"Input Image\", fontsize=27)\n",
    "            axes[row_idx][0].axis('off')\n",
    "            \n",
    "            # Column 1: Ground truth mask\n",
    "            axes[row_idx][1].imshow(gt_rgb)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][1].set_title(\"Ground Truth Mask\", fontsize=27)\n",
    "            axes[row_idx][1].axis('off')\n",
    "            \n",
    "            # Column 2: Predicted mask from this model\n",
    "            pred_mask = generate_segmentation_mask(model, input_tensor)\n",
    "            pred_rgb = mask_to_rgb(pred_mask)\n",
    "            axes[row_idx][2].imshow(pred_rgb)\n",
    "            if row_idx == 0:\n",
    "                axes[row_idx][2].set_title(f\"{model_dir} \\nPredicted Mask\", fontsize=27)\n",
    "            axes[row_idx][2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        merged_filename = os.path.join(predictions_dir, \"All_Models_Predictions.png\")\n",
    "        # Save the figure at high resolution\n",
    "        plt.savefig(merged_filename, bbox_inches='tight', dpi=300)\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Automatically gather all directories starting with \"Unet-\"\n",
    "# ------------------------------------------------------------------------------\n",
    "model_directories = [d for d in os.listdir('.') if os.path.isdir(d) and d.startswith(\"Unet\")]\n",
    "\n",
    "# Name of the Excel file in each model directory\n",
    "excel_filename = \"Performance_Evaluation_Metrics.xlsx\"\n",
    "\n",
    "# Loop over each found model directory\n",
    "for model_dir in model_directories:\n",
    "    # Construct the full path to the Excel file\n",
    "    excel_path = os.path.join(model_dir, excel_filename)\n",
    "    \n",
    "    # Skip this directory if the file does not exist\n",
    "    if not os.path.isfile(excel_path):\n",
    "        continue\n",
    "    \n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(excel_path)\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    # Get the last (bottom) row from the DataFrame\n",
    "    last_row = df.iloc[-1]\n",
    "    \n",
    "    # ------------------ Overall Metrics ------------------\n",
    "    overall_metrics = {\n",
    "        \"Metric\": [\n",
    "            \"Accuracy\",\n",
    "            \"Precision\",\n",
    "            \"Recall\",\n",
    "            \"F1 Score\",\n",
    "            \"Mean IoU\",\n",
    "            \"Frequency Weighted IoU\",\n",
    "            \"Mean Dice\",\n",
    "            \"Mean Jaccard\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            last_row[\"Accuracy\"],\n",
    "            last_row[\"Precision\"],\n",
    "            last_row[\"Recall\"],\n",
    "            last_row[\"F1 Score\"],\n",
    "            last_row[\"Mean IoU\"],\n",
    "            last_row[\"Frequency Weighted IoU\"],\n",
    "            last_row[\"Mean Dice\"],\n",
    "            last_row[\"Mean Jaccard\"]\n",
    "        ]\n",
    "    }\n",
    "    overall_df = pd.DataFrame(overall_metrics)\n",
    "    \n",
    "    # ------------------ Per-Class Metrics ------------------\n",
    "    per_class_data = {\n",
    "        \"Class\": [\"Class 0\", \"Class 1\", \"Class 2\"],\n",
    "        \"Accuracy\": [\n",
    "            last_row[\"Accuracy Class 0\"],\n",
    "            last_row[\"Accuracy Class 1\"],\n",
    "            last_row[\"Accuracy Class 2\"]\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            last_row[\"Precision Class 0\"],\n",
    "            last_row[\"Precision Class 1\"],\n",
    "            last_row[\"Precision Class 2\"]\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            last_row[\"Recall Class 0\"],\n",
    "            last_row[\"Recall Class 1\"],\n",
    "            last_row[\"Recall Class 2\"]\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            last_row[\"F1 Score Class 0\"],\n",
    "            last_row[\"F1 Score Class 1\"],\n",
    "            last_row[\"F1 Score Class 2\"]\n",
    "        ],\n",
    "        \"IoU\": [\n",
    "            last_row[\"IoU Class 0\"],\n",
    "            last_row[\"IoU Class 1\"],\n",
    "            last_row[\"IoU Class 2\"]\n",
    "        ],\n",
    "        \"Dice\": [\n",
    "            last_row[\"Dice Coefficient Class 0\"],\n",
    "            last_row[\"Dice Coefficient Class 1\"],\n",
    "            last_row[\"Dice Coefficient Class 2\"]\n",
    "        ],\n",
    "        \"Jaccard\": [\n",
    "            last_row[\"Jaccard Index Class 0\"],\n",
    "            last_row[\"Jaccard Index Class 1\"],\n",
    "            last_row[\"Jaccard Index Class 2\"]\n",
    "        ]\n",
    "    }\n",
    "    per_class_df = pd.DataFrame(per_class_data)\n",
    "    \n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 3) Save the new Excel files in a Results subfolder of the model directory\n",
    "    # ------------------------------------------------------------------------------\n",
    "    results_dir = os.path.join(model_dir, \"Results\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    overall_excel_path = os.path.join(results_dir, \"Overall_Metrics.xlsx\")\n",
    "    per_class_excel_path = os.path.join(results_dir, \"Per_Class_Metrics.xlsx\")\n",
    "    \n",
    "    overall_df.to_excel(overall_excel_path, index=False)\n",
    "    per_class_df.to_excel(per_class_excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating All Models Perdormance Evaluation Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Path to the merged Excel file\n",
    "# ------------------------------------------------------------------------------\n",
    "merged_excel_path = os.path.join(\"Results\", \"All_Models_Performance_Evaluation_Metrics.xlsx\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Read the Excel file into a DataFrame\n",
    "# ------------------------------------------------------------------------------\n",
    "df = pd.read_excel(merged_excel_path)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Mapping to change model names\n",
    "# ------------------------------------------------------------------------------\n",
    "name_mapping = {\n",
    "    \"unet_best_model.pth\": \"Unet\",\n",
    "    \"unetplusplus_best_model.pth\": \"Unet++\",\n",
    "    \"manet_best_model.pth\": \"MAnet\",\n",
    "    \"linknet_best_model.pth\": \"Linknet\",\n",
    "    \"fpn_best_model.pth\": \"FPN\",\n",
    "    \"pspnet_best_model.pth\": \"PSPNet\",\n",
    "    \"pan_best_model.pth\": \"PAN\",\n",
    "    \"deeplabv3_best_model.pth\": \"DeepLabV3\",\n",
    "    \"deeplabv3plus_best_model.pth\": \"DeepLabV3+\",\n",
    "    \"upernet_best_model.pth\": \"UPerNet\",\n",
    "    \"segformer_best_model.pth\": \"Segformer\"\n",
    "}\n",
    "\n",
    "# Update the \"Model Name\" column based on the mapping.\n",
    "# If a model name is not found in the mapping, leave it unchanged.\n",
    "df[\"Model Name\"] = df[\"Model Name\"].apply(lambda x: name_mapping.get(x, x))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Create Overall Metrics DataFrame\n",
    "# ------------------------------------------------------------------------------\n",
    "overall_columns = [\n",
    "    \"Model Name\",\n",
    "    \"Accuracy\",\n",
    "    \"Precision\",\n",
    "    \"Recall\",\n",
    "    \"F1 Score\",\n",
    "    \"Mean IoU\",\n",
    "    \"Weighted IoU\",\n",
    "    \"Frequency Weighted IoU\",\n",
    "    \"Mean Dice\",\n",
    "    \"Mean Jaccard\"\n",
    "]\n",
    "overall_df = df[overall_columns].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) Create Per-Class Metrics DataFrame\n",
    "# ------------------------------------------------------------------------------\n",
    "per_class_columns = [\n",
    "    \"Model Name\",\n",
    "    \"Accuracy Class 0\", \"Accuracy Class 1\", \"Accuracy Class 2\",\n",
    "    \"Precision Class 0\", \"Precision Class 1\", \"Precision Class 2\",\n",
    "    \"Recall Class 0\", \"Recall Class 1\", \"Recall Class 2\",\n",
    "    \"F1 Score Class 0\", \"F1 Score Class 1\", \"F1 Score Class 2\",\n",
    "    \"IoU Class 0\", \"IoU Class 1\", \"IoU Class 2\",\n",
    "    \"Dice Coefficient Class 0\", \"Dice Coefficient Class 1\", \"Dice Coefficient Class 2\",\n",
    "    \"Jaccard Index Class 0\", \"Jaccard Index Class 1\", \"Jaccard Index Class 2\"\n",
    "]\n",
    "per_class_df = df[per_class_columns].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6) Save the two DataFrames to Excel (overwrite if re-executed)\n",
    "# ------------------------------------------------------------------------------\n",
    "overall_excel_path = os.path.join(\"Results\", \"Overall_Metrics.xlsx\")\n",
    "per_class_excel_path = os.path.join(\"Results\", \"Per_Class_Metrics.xlsx\")\n",
    "\n",
    "overall_df.to_excel(overall_excel_path, index=False)\n",
    "per_class_df.to_excel(per_class_excel_path, index=False)\n",
    "\n",
    "print(f\"Saved overall metrics to: {overall_excel_path}\")\n",
    "print(f\"Saved per-class metrics to: {per_class_excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
